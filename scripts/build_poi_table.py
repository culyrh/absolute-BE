import os
import time
import math
import requests
import psycopg2
import pandas as pd
from psycopg2.extras import execute_values
from dotenv import load_dotenv

# ====== 1. ì„¤ì • ======
KAKAO_REST_API_KEY = "23f88060feff03f24c4dc64807d2201c"  # í‚¤ êµì²´

# train / test CSV ê²½ë¡œ
TRAIN_CSV = "data/train.csv"
TEST_CSV  = "data/test_data.csv"   # ì˜µì…˜

# Kakao Local API endpoint
KAKAO_LOCAL_URL = "https://dapi.kakao.com/v2/local/search/category.json"

load_dotenv()  # .env ìë™ ë¡œë“œ

# PostgreSQL ì—°ê²° ì •ë³´
self.conn = psycopg2.connect(
    host=os.getenv("POSTGRES_HOST"),
    port=os.getenv("POSTGRES_PORT"),
    dbname=os.getenv("POSTGRES_DB"),
    user=os.getenv("POSTGRES_USER"),
    password=os.getenv("POSTGRES_PASSWORD")
)


# category_group_code -> (ìš°ë¦¬ ì¹´í…Œê³ ë¦¬ëª…)
CATEGORY_CONFIG = {
    "CS2": "í¸ì˜ì ",
    "AD5": "ìˆ™ë°•ì‹œì„¤",
    "FD6": "ìŒì‹ì ",
}


# ====== 2. Kakao API í˜¸ì¶œ í•¨ìˆ˜ ======
def kakao_category_search(lon, lat, category_code, radius=500, max_pages=3, size=15):
    """
    Kakao Local category search
    - lon, lat: WGS84 ì¢Œí‘œ
    - category_code: 'CS2', 'AD5', 'FD6'
    - radius: m (ìµœëŒ€ 20000, ìš°ë¦¬ëŠ” 500m)
    - max_pages: ìµœëŒ€ ëª‡ í˜ì´ì§€ê¹Œì§€ ë³¼ì§€ (ê¸°ë³¸ 3í˜ì´ì§€ => ìµœëŒ€ 45ê°œ)
    """
    headers = {
        "Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"
    }

    results = []

    for page in range(1, max_pages + 1):
        params = {
            "category_group_code": category_code,
            "x": lon,
            "y": lat,
            "radius": radius,
            "page": page,
            "size": size,
            "sort": "distance",
        }

        resp = requests.get(KAKAO_LOCAL_URL, headers=headers, params=params, timeout=5)
        if resp.status_code != 200:
            print(f"âš ï¸ Kakao API ì‹¤íŒ¨: {resp.status_code}, {resp.text[:200]}")
            break

        data = resp.json()
        docs = data.get("documents", [])
        meta = data.get("meta", {})

        results.extend(docs)

        is_end = meta.get("is_end", True)
        if is_end or not docs:
            break

        # ë„ˆë¬´ ë¹ ë¥´ê²Œ ë•Œë¦¬ì§€ ì•Šë„ë¡
        time.sleep(0.15)

    return results


# ====== 3. poi í…Œì´ë¸”ì— INSERT ======
def insert_poi_rows(conn, rows):
    """
    rows: list of dicts
    dict keys: (station_id, src, category, name, address, lat, lon)
    geomì€ INSERT ì‹œ PostGIS í•¨ìˆ˜ë¡œ ìƒì„±
    """
    if not rows:
        return

    with conn.cursor() as cur:
        values = [
            (
                r["station_id"],
                r["src"],
                r["category"],
                r["name"],
                r["address"],
                r["lat"],
                r["lon"],
            )
            for r in rows
        ]

        sql = """
        INSERT INTO poi (station_id, src, category, name, address, lat, lon, geom)
        VALUES %s
        ON CONFLICT (category, lon, lat) DO NOTHING;
        """

        # geomì€ ì„œë²„ìª½ì—ì„œ ST_Transformìœ¼ë¡œ ìƒì„±
        template = """
        (%s, %s, %s, %s, %s, %s, %s,
         ST_Transform(ST_SetSRID(ST_Point(%s, %s), 4326), 5186)
        )
        """

        geom_values = [
            (
                v[0], v[1], v[2], v[3], v[4], v[5], v[6],
                v[6], v[5]   # â† ë§ˆì§€ë§‰ ë‘ ê°œëŠ” lon, lat (POINT(x,y))
            )
            for v in values
        ]

        # ğŸ”¥ ì—¬ê¸°ì„œ templateë¥¼ ëª…ì‹œí•´ì•¼ í•¨
        execute_values(cur, sql, geom_values, template=template)

    conn.commit()


# ====== 4. ë©”ì¸ ë¡œì§: ì£¼ìœ ì†Œ ë¦¬ìŠ¤íŠ¸ ëŒë©´ì„œ POI ìˆ˜ì§‘ ======
def build_poi_from_csv(csv_path, conn, station_offset=0):
    """
    csv_pathì˜ ëª¨ë“  í–‰(ê° ì£¼ìœ ì†Œ)ì— ëŒ€í•´:
      - ë°˜ê²½ 500m í¸ì˜ì /ìˆ™ë°•ì‹œì„¤/ìŒì‹ì  Kakao ê²€ìƒ‰
      - poi í…Œì´ë¸”ì— upsert
    station_id ëŠ” (station_offset + df.index) ë¡œ ë¶€ì—¬
    """
    print(f"ğŸ“‚ CSV ë¡œë“œ: {csv_path}")
    df = pd.read_csv(csv_path)

    if not {"ìœ„ë„", "ê²½ë„"}.issubset(df.columns):
        raise ValueError("CSVì— 'ìœ„ë„', 'ê²½ë„' ì»¬ëŸ¼ì´ í•„ìš”í•¨")

    total = len(df)
    print(f"ğŸ” ëŒ€ìƒ ì£¼ìœ ì†Œ ìˆ˜: {total}ê°œ")

    for idx, row in df.iterrows():
        lat = float(row["ìœ„ë„"])
        lon = float(row["ê²½ë„"])
        station_id = station_offset + int(idx)

        all_new_rows = []

        for code, cat_name in CATEGORY_CONFIG.items():
            docs = kakao_category_search(lon, lat, code, radius=500, max_pages=3, size=15)
            for d in docs:
                try:
                    place_name = d.get("place_name", "")
                    address_name = d.get("road_address_name") or d.get("address_name") or ""
                    x = float(d.get("x"))
                    y = float(d.get("y"))
                except Exception:
                    continue

                all_new_rows.append({
                    "station_id": station_id,
                    "src": "kakao",
                    "category": cat_name,
                    "name": place_name,
                    "address": address_name,
                    "lat": y,
                    "lon": x,
                })

        insert_poi_rows(conn, all_new_rows)

        if station_id % 50 == 0:
            print(f"âœ… ì§„í–‰ì¤‘... {station_id+1}/{station_offset+total} ì£¼ìœ ì†Œ ì™„ë£Œ")

        # ë„ˆë¬´ ë¹ ë¥´ê²Œ ì—°ì† í˜¸ì¶œ ë°©ì§€
        time.sleep(0.1)


def main():
    conn = psycopg2.connect(**PG_CONN_INFO)
    try:
        # ê¸°ì¡´ poi ì „ì²´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ë§Œë“¤ê³  ì‹¶ìœ¼ë©´ ì£¼ì„ í•´ì œ
        # with conn.cursor() as cur:
        #     cur.execute("TRUNCATE TABLE poi;")
        # conn.commit()

        # 1) train.csv ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì§‘
        build_poi_from_csv(TRAIN_CSV, conn, station_offset=0)

        # 2) test_data.csvê¹Œì§€ ì´ì–´ì„œ ë„£ê³  ì‹¶ìœ¼ë©´ ì£¼ì„ í•´ì œ
        # build_poi_from_csv(TEST_CSV, conn, station_offset=10000)

        print("ğŸ‰ POI ìˆ˜ì§‘ ë° ì €ì¥ ì™„ë£Œ")
    finally:
        conn.close()


if __name__ == "__main__":
    main()

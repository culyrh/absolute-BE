"""
ì¶”ì²œ ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤
"""

import pandas as pd
import numpy as np
import re
import math
from typing import Dict, List, Tuple, Optional, Union, Any
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity
from scipy.spatial.distance import euclidean
from scipy.stats import pearsonr

from app.utils.data_loader import load_all_data, find_column_by_keyword
from app.utils.preprocessing import (
    preprocess_gas_station_data, merge_with_stats, normalize_features,
    categorize_by_usage_type_and_region, calculate_centroids,
    extract_admin_region, extract_province, normalize_region
)
from app.schemas.recommendation import RecommendationAlgorithm, RecommendationResponse
from app.core.config import settings


class RecommendationService:
    """ì¶”ì²œ ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.data = None
        self.centroids = None
        self.feature_cols = ["ì¸êµ¬[ëª…]", "êµí†µëŸ‰", "ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)", "ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)", "ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)"]
        self.norm_cols = [f"{col}_norm" for col in self.feature_cols]
        self.initialize_data()
    
    def initialize_data(self):
        """ë°ì´í„° ì´ˆê¸°í™” ë° ë¡œë“œ"""
        print("ğŸš€ ì¶”ì²œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        
        # ëª¨ë“  ë°ì´í„° ë¡œë“œ
        self.data = load_all_data()
        
        # ì£¼ìœ ì†Œ ë°ì´í„° ì „ì²˜ë¦¬
        self.data["gas_station"] = preprocess_gas_station_data(self.data["gas_station"])
        
        # ì¸êµ¬ìˆ˜ì™€ ì‚¬ì—…ì²´ ë°ì´í„° ë³‘í•©
        self.data["gas_station"] = merge_with_stats(
            self.data["gas_station"],
            self.data["population"],
            self.data["business"]
        )
        
        # íŠ¹ì§• ì •ê·œí™”
        available_cols = [col for col in self.feature_cols if col in self.data["gas_station"].columns]
        self.data["gas_station"] = normalize_features(self.data["gas_station"], available_cols)
        
        # ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„° ì²˜ë¦¬
        self.process_centroids()
        
        print("âœ… ì¶”ì²œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process_centroids(self):
        """ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„° ì²˜ë¦¬"""
        # ëŒ€ë¶„ë¥˜_ì„¼í„°ë¡œì´ë“œ.csv íŒŒì¼ì—ì„œ ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„° í™œìš©
        try:
            self.centroids = self.data["centroid"].copy()
            print(f"ğŸ“Š ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(self.centroids)}ê°œ")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„° ì‚¬ìš© ì‹¤íŒ¨: {str(e)}")
            
            # ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv íŒŒì¼ì—ì„œ ëŒ€ë¶„ë¥˜ì™€ ê¶Œì—­ë³„ë¡œ ë°ì´í„° ë¶„ë¥˜ ë° ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚°
            try:
                recommend_data = self.data["recommend_result"]
                
                # ë°ì´í„° ë¶„ë¥˜
                grouped_data = categorize_by_usage_type_and_region(recommend_data)
                
                # ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚°
                available_cols = [col for col in self.norm_cols if col in recommend_data.columns]
                self.centroids = calculate_centroids(grouped_data, available_cols, method="median")
                
                print(f"ğŸ“Š ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚° ì™„ë£Œ: {len(self.centroids)}ê°œ")
            except Exception as e:
                print(f"âš ï¸ ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
                
                # ë¹ˆ ì„¼íŠ¸ë¡œì´ë“œ ìƒì„±
                self.centroids = pd.DataFrame(columns=["usage_type", "region"] + self.norm_cols)
    
    def recommend_by_query(self, 
                          query: str, 
                          algorithm: RecommendationAlgorithm = RecommendationAlgorithm.COSINE_SIMILARITY,
                          top_k: int = 10,
                          region: Optional[str] = None) -> RecommendationResponse:
        """ì£¼ì†Œ ê¸°ë°˜ ì¶”ì²œ"""
        if not query:
            return {"query": query, "timestamp": datetime.now(), "algorithm": algorithm, "count": 0, "items": []}
        
        # ì£¼ì†Œ ê²€ìƒ‰
        gas_df = self.data["gas_station"]
        filtered_df = gas_df[gas_df["ì£¼ì†Œ"].astype(str).str.contains(query, na=False)]
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ í–‰ì •êµ¬ì—­ìœ¼ë¡œ ê²€ìƒ‰
        if filtered_df.empty:
            filtered_df = gas_df[gas_df["í–‰ì •êµ¬ì—­"].astype(str).str.contains(query, na=False)]
        
        # ì—¬ì „íˆ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
        if filtered_df.empty:
            return {"query": query, "timestamp": datetime.now(), "algorithm": algorithm, "count": 0, "items": []}
        
        # ê¶Œì—­ í•„í„°ë§
        if region:
            normalized_region = normalize_region(region)
            filtered_df = filtered_df[filtered_df["ê¶Œì—­"] == normalized_region]
        
        # ì„¼íŠ¸ë¡œì´ë“œì™€ ë¹„êµí•˜ì—¬ ì¶”ì²œ
        if algorithm == RecommendationAlgorithm.POPULARITY:
            recommendations = self.recommend_by_popularity(filtered_df, top_k)
        elif algorithm == RecommendationAlgorithm.COLLABORATIVE:
            recommendations = self.recommend_by_collaborative_filtering(filtered_df, top_k)
        elif algorithm == RecommendationAlgorithm.PEARSON_CORRELATION:
            recommendations = self.recommend_by_pearson_correlation(filtered_df, top_k)
        elif algorithm == RecommendationAlgorithm.EUCLIDEAN_DISTANCE:
            recommendations = self.recommend_by_euclidean_distance(filtered_df, top_k)
        elif algorithm == RecommendationAlgorithm.AHP_TOPSIS:
            recommendations = self.recommend_by_ahp_topsis(filtered_df, top_k, region)
        else:  # ê¸°ë³¸ê°’: ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            recommendations = self.recommend_by_cosine_similarity(filtered_df, top_k)
        
        # ê²°ê³¼ í˜•ì‹í™”
        return {
            "query": query,
            "timestamp": datetime.now(),
            "algorithm": algorithm,
            "count": len(recommendations),
            "items": recommendations
        }
    
    def recommend_by_popularity(self, df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            # ëŒ€ë¶„ë¥˜ ë¹ˆë„ìˆ˜ ê³„ì‚° (ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv íŒŒì¼ í™œìš©)
            recommend_df = self.data["recommend_result"]
            usage_type_counts = recommend_df["ëŒ€ë¶„ë¥˜"].value_counts().reset_index()
            usage_type_counts.columns = ["usage_type", "count"]
            
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_usage_types = usage_type_counts.head(top_k)
            
            # ê²°ê³¼ í˜•ì‹í™”
            recommendations = []
            
            for i, (_, row) in enumerate(top_usage_types.iterrows()):
                usage_type = row["usage_type"]
                count = row["count"]
                
                # ì²« ë²ˆì§¸ ì£¼ì†Œ ì‚¬ìš©
                if len(df) > 0:
                    address_row = df.iloc[0]
                    address = address_row.get("ì£¼ì†Œ", "")
                    admin_region = address_row.get("í–‰ì •êµ¬ì—­", "")
                    population = float(address_row.get("ì¸êµ¬[ëª…]", 0))
                    business_density = float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0))
                    
                    recommendations.append({
                        "address": address,
                        "admin_region": admin_region,
                        "usage_type": usage_type,
                        "score": float(count / usage_type_counts["count"].max()),
                        "rank": i + 1,
                        "population": population,
                        "business_density": business_density,
                        "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                        "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                        "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                        "station_status": address_row.get("ìƒíƒœ", ""),
                        "note": address_row.get("ë¹„ê³ ", "")
                    })
            
            return recommendations
        
        except Exception as e:
            print(f"âš ï¸ ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def recommend_by_cosine_similarity(self, df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            if len(df) == 0 or len(self.centroids) == 0:
                return []
            
            # ì²« ë²ˆì§¸ ì£¼ì†Œì˜ ë²¡í„° ì¶”ì¶œ
            address_row = df.iloc[0]
            
            # í•„ìš”í•œ ë²¡í„° í™•ì¸
            available_norm_cols = [col for col in self.norm_cols if col in self.centroids.columns]
            
            if not available_norm_cols:
                return []
            
            # ì£¼ì†Œ ë²¡í„° ìƒì„±
            address_vector = np.array([address_row.get(col, 0) for col in available_norm_cols]).reshape(1, -1)
            
            # ì„¼íŠ¸ë¡œì´ë“œ ë²¡í„° ìƒì„±
            centroids_vectors = self.centroids[available_norm_cols].values
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = cosine_similarity(address_vector, centroids_vectors)[0]
            
            # ìœ ì‚¬ë„ì™€ ì„¼íŠ¸ë¡œì´ë“œ ì •ë³´ ê²°í•©
            similarity_df = self.centroids.copy()
            similarity_df["similarity"] = similarities
            
            # ìœ ì‚¬ë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            similarity_df = similarity_df.sort_values("similarity", ascending=False)
            
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_centroids = similarity_df.head(top_k)
            
            # ê²°ê³¼ í˜•ì‹í™”
            recommendations = []
            
            for i, (_, centroid) in enumerate(top_centroids.iterrows()):
                recommendations.append({
                    "address": address_row.get("ì£¼ì†Œ", ""),
                    "admin_region": address_row.get("í–‰ì •êµ¬ì—­", ""),
                    "usage_type": centroid.get("usage_type", ""),
                    "score": float(centroid.get("similarity", 0)),
                    "rank": i + 1,
                    "population": float(address_row.get("ì¸êµ¬[ëª…]", 0)),
                    "business_density": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0)),
                    "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                    "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                    "traffic_norm": float(centroid.get("êµí†µëŸ‰_norm", 0)),
                    "tourism_norm": float(centroid.get("ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)_norm", 0)),
                    "land_price_norm": float(centroid.get("ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)_norm", 0)),
                    "similarity": float(centroid.get("similarity", 0)),
                    "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                    "station_status": address_row.get("ìƒíƒœ", ""),
                    "note": address_row.get("ë¹„ê³ ", "")
                })
            
            return recommendations
        
        except Exception as e:
            print(f"âš ï¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def recommend_by_euclidean_distance(self, df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            if len(df) == 0 or len(self.centroids) == 0:
                return []
            
            # ì²« ë²ˆì§¸ ì£¼ì†Œì˜ ë²¡í„° ì¶”ì¶œ
            address_row = df.iloc[0]
            
            # í•„ìš”í•œ ë²¡í„° í™•ì¸
            available_norm_cols = [col for col in self.norm_cols if col in self.centroids.columns]
            
            if not available_norm_cols:
                return []
            
            # ì£¼ì†Œ ë²¡í„° ìƒì„±
            address_vector = np.array([address_row.get(col, 0) for col in available_norm_cols])
            
            # ì„¼íŠ¸ë¡œì´ë“œì™€ ê±°ë¦¬ ê³„ì‚°
            distances = []
            
            for _, centroid in self.centroids.iterrows():
                # ì„¼íŠ¸ë¡œì´ë“œ ë²¡í„° ìƒì„±
                centroid_vector = np.array([centroid.get(col, 0) for col in available_norm_cols])
                
                # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
                try:
                    distance = euclidean(address_vector, centroid_vector)
                except:
                    distance = float('inf')
                
                distances.append({
                    "usage_type": centroid.get("usage_type", ""),
                    "region": centroid.get("region", ""),
                    "distance": distance,
                    **{col: centroid.get(col, 0) for col in available_norm_cols}
                })
            
            # ê±°ë¦¬ ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
            sorted_distances = sorted(distances, key=lambda x: x["distance"])
            
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_centroids = sorted_distances[:top_k]
            
            # ê²°ê³¼ í˜•ì‹í™”
            recommendations = []
            
            for i, centroid in enumerate(top_centroids):
                # ê±°ë¦¬ ì ìˆ˜ ë³€í™˜ (0~1, ê°€ê¹Œìš¸ìˆ˜ë¡ 1)
                max_distance = sorted_distances[-1]["distance"] if len(sorted_distances) > 0 else 1
                score = 1 - (centroid["distance"] / max_distance if max_distance > 0 else 0)
                
                recommendations.append({
                    "address": address_row.get("ì£¼ì†Œ", ""),
                    "admin_region": address_row.get("í–‰ì •êµ¬ì—­", ""),
                    "usage_type": centroid.get("usage_type", ""),
                    "score": float(score),
                    "rank": i + 1,
                    "population": float(address_row.get("ì¸êµ¬[ëª…]", 0)),
                    "business_density": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0)),
                    "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                    "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                    "traffic_norm": float(centroid.get("êµí†µëŸ‰_norm", 0)),
                    "tourism_norm": float(centroid.get("ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)_norm", 0)),
                    "land_price_norm": float(centroid.get("ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)_norm", 0)),
                    "distance": float(centroid.get("distance", 0)),
                    "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                    "station_status": address_row.get("ìƒíƒœ", ""),
                    "note": address_row.get("ë¹„ê³ ", "")
                })
            
            return recommendations
        
        except Exception as e:
            print(f"âš ï¸ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def recommend_by_pearson_correlation(self, df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            if len(df) == 0 or len(self.centroids) == 0:
                return []
            
            # ì²« ë²ˆì§¸ ì£¼ì†Œì˜ ë²¡í„° ì¶”ì¶œ
            address_row = df.iloc[0]
            
            # í•„ìš”í•œ ë²¡í„° í™•ì¸
            available_norm_cols = [col for col in self.norm_cols if col in self.centroids.columns]
            
            if not available_norm_cols:
                return []
            
            # ì£¼ì†Œ ë²¡í„° ìƒì„±
            address_vector = np.array([address_row.get(col, 0) for col in available_norm_cols])
            
            # ì„¼íŠ¸ë¡œì´ë“œì™€ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            correlations = []
            
            for _, centroid in self.centroids.iterrows():
                # ì„¼íŠ¸ë¡œì´ë“œ ë²¡í„° ìƒì„±
                centroid_vector = np.array([centroid.get(col, 0) for col in available_norm_cols])
                
                # í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
                try:
                    correlation, _ = pearsonr(address_vector, centroid_vector)
                    if math.isnan(correlation):
                        correlation = 0
                except:
                    correlation = 0
                
                correlations.append({
                    "usage_type": centroid.get("usage_type", ""),
                    "region": centroid.get("region", ""),
                    "correlation": correlation,
                    **{col: centroid.get(col, 0) for col in available_norm_cols}
                })
            
            # ìƒê´€ê³„ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            sorted_correlations = sorted(correlations, key=lambda x: x["correlation"], reverse=True)
            
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_centroids = sorted_correlations[:top_k]
            
            # ê²°ê³¼ í˜•ì‹í™”
            recommendations = []
            
            for i, centroid in enumerate(top_centroids):
                # ìƒê´€ê³„ìˆ˜ ì ìˆ˜ ë³€í™˜ (-1~1 -> 0~1)
                score = (centroid["correlation"] + 1) / 2
                
                recommendations.append({
                    "address": address_row.get("ì£¼ì†Œ", ""),
                    "admin_region": address_row.get("í–‰ì •êµ¬ì—­", ""),
                    "usage_type": centroid.get("usage_type", ""),
                    "score": float(score),
                    "rank": i + 1,
                    "population": float(address_row.get("ì¸êµ¬[ëª…]", 0)),
                    "business_density": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0)),
                    "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                    "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                    "traffic_norm": float(centroid.get("êµí†µëŸ‰_norm", 0)),
                    "tourism_norm": float(centroid.get("ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)_norm", 0)),
                    "land_price_norm": float(centroid.get("ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)_norm", 0)),
                    "similarity": float(centroid.get("correlation", 0)),
                    "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                    "station_status": address_row.get("ìƒíƒœ", ""),
                    "note": address_row.get("ë¹„ê³ ", "")
                })
            
            return recommendations
        
        except Exception as e:
            print(f"âš ï¸ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def recommend_by_collaborative_filtering(self, df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            # ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv íŒŒì¼ í™œìš©
            recommend_df = self.data["recommend_result"]
            
            if len(df) == 0 or len(recommend_df) == 0:
                return []
            
            # ì²« ë²ˆì§¸ ì£¼ì†Œ ì •ë³´
            address_row = df.iloc[0]
            address_region = address_row.get("ê¶Œì—­", "")
            
            # ì£¼ì†Œì˜ ê¶Œì—­ê³¼ ì¼ì¹˜í•˜ëŠ” í–‰ ì„ íƒ
            region_recommend = recommend_df[recommend_df["ê¶Œì—­"] == address_region]
            
            if len(region_recommend) == 0:
                # ê¶Œì—­ì´ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©
                region_recommend = recommend_df
            
            # ëŒ€ë¶„ë¥˜ë³„ í‰ê·  ì¶”ì²œ ì ìˆ˜ ê³„ì‚°
            usage_type_scores = region_recommend.groupby("ëŒ€ë¶„ë¥˜")["ì¶”ì²œ_ëŒ€ë¶„ë¥˜"].count().reset_index()
            usage_type_scores.columns = ["usage_type", "count"]
            
            # ì ìˆ˜ ì •ê·œí™”
            total_count = usage_type_scores["count"].sum()
            usage_type_scores["score"] = usage_type_scores["count"] / total_count if total_count > 0 else 0
            
            # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            usage_type_scores = usage_type_scores.sort_values("score", ascending=False)
            
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_usage_types = usage_type_scores.head(top_k)
            
            # ê²°ê³¼ í˜•ì‹í™”
            recommendations = []
            
            for i, (_, row) in enumerate(top_usage_types.iterrows()):
                usage_type = row["usage_type"]
                score = row["score"]
                
                recommendations.append({
                    "address": address_row.get("ì£¼ì†Œ", ""),
                    "admin_region": address_row.get("í–‰ì •êµ¬ì—­", ""),
                    "usage_type": usage_type,
                    "score": float(score),
                    "rank": i + 1,
                    "population": float(address_row.get("ì¸êµ¬[ëª…]", 0)),
                    "business_density": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0)),
                    "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                    "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                    "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                    "station_status": address_row.get("ìƒíƒœ", ""),
                    "note": address_row.get("ë¹„ê³ ", "")
                })
            
            return recommendations
        
        except Exception as e:
            print(f"âš ï¸ í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def recommend_by_ahp_topsis(self, df: pd.DataFrame, top_k: int = 10, region: Optional[str] = None) -> List[Dict[str, Any]]:
        """ê¶Œì—­ ê¸°ë°˜ AHP-TOPSIS ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜"""
        try:
            if len(df) == 0:
                return []
        
            # ì²« ë²ˆì§¸ ì£¼ì†Œì˜ ì •ë³´ ì¶”ì¶œ
            address_row = df.iloc[0]
            address_region = address_row.get("ê¶Œì—­", "")
        
            # ê¶Œì—­ì´ ì—†ëŠ” ê²½ìš°, extract_province í•¨ìˆ˜ë¡œ ì£¼ì†Œì—ì„œ ì¶”ì¶œ ì‹œë„
            if not address_region:
                address = address_row.get("ì£¼ì†Œ", "")
                address_region = extract_province(address)
        
            # ê¶Œì—­ ì •ê·œí™”
            if region:
                # ì‚¬ìš©ìê°€ ì§€ì •í•œ ê¶Œì—­ ì‚¬ìš©
                address_region = normalize_region(region)
            elif address_region:
                # ì¶”ì¶œëœ ê¶Œì—­ ì •ê·œí™”
                address_region = normalize_region(address_region)
            else:
                # ê¶Œì—­ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ "ì „ë¼ë¶ë„" ì‚¬ìš©
                address_region = "ì „ë¼ë¶ë„"
        
            # ì¶”ì²œ ê²°ê³¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            recommend_df = self.data.get("recommend_result", pd.DataFrame())
        
            # ê¶Œì—­ë³„ ë°ì´í„° í•„í„°ë§
            region_df = recommend_df[recommend_df["ê¶Œì—­"] == address_region] if "ê¶Œì—­" in recommend_df.columns else recommend_df
        
            if len(region_df) == 0:
                return []
        
            # 1. AHP ê°€ì¤‘ì¹˜ ì •ì˜ (4ê°œ ì§€í‘œ)
            # ì—¬ê¸°ì„œëŠ” ê³ ì •ëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ìŒëŒ€ë¹„êµí–‰ë ¬ë¡œë¶€í„° ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            weights = {
                "ì¸êµ¬[ëª…]_norm": 0.30,           # ì¸êµ¬ë°€ë„
                "êµí†µëŸ‰_norm": 0.25,             # êµí†µëŸ‰
                "ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)_norm": 0.20,  # ê´€ê´‘ì§€ìˆ˜
                "ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)_norm": 0.25     # ìƒê¶Œë°€ì§‘ë„
            }
        
            # ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì§• ì»¬ëŸ¼ í™•ì¸
            available_cols = [col for col in weights.keys() if col in address_row.index]
        
            if not available_cols:
                return []
        
            # 2. ê° ëŒ€ì•ˆ(ìš©ë„ ìœ í˜•)ë³„ ì§€í‘œ ì¤‘ìœ„ê°’ ê³„ì‚°
            usage_types = region_df["ëŒ€ë¶„ë¥˜"].unique() if "ëŒ€ë¶„ë¥˜" in region_df.columns else []

            if len(usage_types) == 0:
                # ëŒ€ì•ˆì´ ì—†ëŠ” ê²½ìš°, ê¸°ë³¸ ëŒ€ì•ˆ ì‚¬ìš©
                usage_types = [
                    "ê·¼ë¦°ìƒí™œì‹œì„¤", "ê³µë™ì£¼íƒ", "ìë™ì°¨ê´€ë ¨ì‹œì„¤", 
                    "íŒë§¤ì‹œì„¤", "ì—…ë¬´ì‹œì„¤", "ìˆ™ë°•ì‹œì„¤",
                    "ê³µì¥", "ê°€ì„¤ê±´ì¶•", "ê¸°íƒ€"
                ]
        
            # 3. ê²°ì • í–‰ë ¬ ìƒì„±
            decision_matrix = {}
        
            for usage_type in usage_types:
                # í•´ë‹¹ ìš©ë„ ìœ í˜•ê³¼ ê¶Œì—­ì˜ ë°ì´í„° í•„í„°ë§
                type_df = region_df[region_df["ëŒ€ë¶„ë¥˜"] == usage_type] if "ëŒ€ë¶„ë¥˜" in region_df.columns else pd.DataFrame()
            
                if len(type_df) > 0:
                    # ì¤‘ìœ„ê°’ ê³„ì‚°
                    medians = {}
                    for col in available_cols:
                        if col in type_df.columns:
                            medians[col] = type_df[col].median()
                        else:
                            medians[col] = 0.5  # ê¸°ë³¸ê°’

                    decision_matrix[usage_type] = medians
                else:
                    # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
                    decision_matrix[usage_type] = {col: 0.5 for col in available_cols}
        
            # 4. ëŒ€ìƒ ì£¼ìœ ì†Œì˜ ì§€í‘œ ê°’ ì¶”ì¶œ
            site_values = {}
            for col in available_cols:
                site_values[col] = float(address_row.get(col, 0))
        
            # 5. TOPSIS ì•Œê³ ë¦¬ì¦˜ ì ìš©
            # 5.1. ìœ ì‚¬ë„ ì ìˆ˜ í–‰ë ¬ ìƒì„± (ëŒ€ìƒ ì£¼ìœ ì†Œì™€ ê° ìš©ë„ ìœ í˜•ì˜ ì¤‘ìœ„ê°’ ê°„ ìœ ì‚¬ë„)
            similarity_matrix = {}
        
            for usage_type, medians in decision_matrix.items():
                distances = {}

                for col in available_cols:
                    # ì ˆëŒ€ ê±°ë¦¬ ê³„ì‚°
                    distance = abs(site_values[col] - medians[col])
                    distances[col] = 1 - distance  # ìœ ì‚¬ë„ë¡œ ë³€í™˜ (ê°’ì´ í´ìˆ˜ë¡ ìœ ì‚¬)

                similarity_matrix[usage_type] = distances

            # 5.2. ì •ê·œí™” ë° ê°€ì¤‘ì¹˜ ì ìš©
            weighted_matrix = {}
        
            for usage_type, similarities in similarity_matrix.items():
                weighted = {}

                for col in available_cols:
                    weighted[col] = weights.get(col, 0) * similarities[col]

                weighted_matrix[usage_type] = weighted

            # 5.3. ì´ìƒí•´ ë° ë°˜ëŒ€í•´ ê³„ì‚°
            ideal_positive = {}
            ideal_negative = {}
        
            for col in available_cols:
                max_val = max(weighted_matrix[ut][col] for ut in weighted_matrix)
                min_val = min(weighted_matrix[ut][col] for ut in weighted_matrix)

                ideal_positive[col] = max_val
                ideal_negative[col] = min_val
        
            # 5.4. ê±°ë¦¬ ê³„ì‚°
            distances_positive = {}
            distances_negative = {}
        
            for usage_type, weighted in weighted_matrix.items():
                # ì´ìƒí•´ì™€ì˜ ê±°ë¦¬
                dist_pos = sum((weighted[col] - ideal_positive[col]) ** 2 for col in available_cols) ** 0.5
                # ë°˜ëŒ€í•´ì™€ì˜ ê±°ë¦¬
                dist_neg = sum((weighted[col] - ideal_negative[col]) ** 2 for col in available_cols) ** 0.5

                distances_positive[usage_type] = dist_pos
                distances_negative[usage_type] = dist_neg
        
            # 5.5. ìƒëŒ€ ê·¼ì ‘ë„ ê³„ì‚°
            closeness = {}

            for usage_type in weighted_matrix:
                d_pos = distances_positive[usage_type]
                d_neg = distances_negative[usage_type]
            
                # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                if d_pos + d_neg == 0:
                    closeness[usage_type] = 0
                else:
                    closeness[usage_type] = d_neg / (d_pos + d_neg)

            # 6. ê²°ê³¼ ì •ë ¬ ë° ìƒìœ„ ì¶”ì²œ ë°˜í™˜
            sorted_results = sorted(
                [(usage_type, score) for usage_type, score in closeness.items()],
                key=lambda x: x[1],
                reverse=True
            )
        
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_results = sorted_results[:top_k]
        
            # 7. ê²°ê³¼ í˜•ì‹í™”
            recommendations = []

            for i, (usage_type, score) in enumerate(top_results):
                recommendations.append({
                    "address": address_row.get("ì£¼ì†Œ", ""),
                    "admin_region": address_row.get("í–‰ì •êµ¬ì—­", ""),
                    "usage_type": usage_type,
                    "score": float(score),
                    "rank": i + 1,
                    "population": float(address_row.get("ì¸êµ¬[ëª…]", 0)),
                    "business_density": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0)),
                    "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                    "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                    "traffic_norm": float(address_row.get("êµí†µëŸ‰_norm", 0) if "êµí†µëŸ‰_norm" in address_row else 0),
                    "tourism_norm": float(address_row.get("ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)_norm", 0) if "ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)_norm" in address_row else 0),
                    "land_price_norm": float(address_row.get("ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)_norm", 0) if "ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)_norm" in address_row else 0),
                    "ahp_weights": weights,  # AHP ê°€ì¤‘ì¹˜ ì •ë³´ ì¶”ê°€
                    "region": address_region,  # ê¶Œì—­ ì •ë³´ ì¶”ê°€
                    "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                    "station_status": address_row.get("ìƒíƒœ", ""),
                    "note": address_row.get("ë¹„ê³ ", "")
                })

            return recommendations

        except Exception as e:
            print(f"âš ï¸ ê¶Œì—­ ê¸°ë°˜ AHP-TOPSIS ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return []
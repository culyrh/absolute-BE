"""
ì¶”ì²œ ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤
"""

import pandas as pd
import numpy as np
import re
import math
from typing import Dict, List, Tuple, Optional, Union, Any
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity
from scipy.spatial.distance import euclidean
from scipy.stats import pearsonr

from app.utils.data_loader import load_all_data, find_column_by_keyword
from app.utils.preprocessing import (
    preprocess_gas_station_data, merge_with_stats, normalize_features,
    categorize_by_usage_type_and_region, calculate_centroids,
    extract_admin_region, extract_province, normalize_region
)
from app.schemas.recommendation import RecommendationAlgorithm, RecommendationResponse
from app.core.config import settings


class RecommendationService:
    """ì¶”ì²œ ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.data = None
        self.centroids = None
        self.feature_cols = ["ì¸êµ¬[ëª…]", "êµí†µëŸ‰", "ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)", "ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)", "ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)"]
        self.norm_cols = [f"{col}_norm" for col in self.feature_cols]
        self.initialize_data()
    
    def initialize_data(self):
        """ë°ì´í„° ì´ˆê¸°í™” ë° ë¡œë“œ"""
        print("ğŸš€ ì¶”ì²œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        
        # ëª¨ë“  ë°ì´í„° ë¡œë“œ
        self.data = load_all_data()
        
        # ì£¼ìœ ì†Œ ë°ì´í„° ì „ì²˜ë¦¬
        self.data["gas_station"] = preprocess_gas_station_data(self.data["gas_station"])
        
        # ì¸êµ¬ìˆ˜ì™€ ì‚¬ì—…ì²´ ë°ì´í„° ë³‘í•©
        self.data["gas_station"] = merge_with_stats(
            self.data["gas_station"],
            self.data["population"],
            self.data["business"]
        )
        
        # íŠ¹ì§• ì •ê·œí™”
        available_cols = [col for col in self.feature_cols if col in self.data["gas_station"].columns]
        self.data["gas_station"] = normalize_features(self.data["gas_station"], available_cols)
        
        # ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„° ì²˜ë¦¬
        self.process_centroids()
        
        print("âœ… ì¶”ì²œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process_centroids(self):
        """ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„° ì²˜ë¦¬"""
        # ëŒ€ë¶„ë¥˜_ì„¼í„°ë¡œì´ë“œ.csv íŒŒì¼ì—ì„œ ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„° í™œìš©
        try:
            self.centroids = self.data["centroid"].copy()
            print(f"ğŸ“Š ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(self.centroids)}ê°œ")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„° ì‚¬ìš© ì‹¤íŒ¨: {str(e)}")
            
            # ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv íŒŒì¼ì—ì„œ ëŒ€ë¶„ë¥˜ì™€ ê¶Œì—­ë³„ë¡œ ë°ì´í„° ë¶„ë¥˜ ë° ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚°
            try:
                recommend_data = self.data["recommend_result"]
                
                # ë°ì´í„° ë¶„ë¥˜
                grouped_data = categorize_by_usage_type_and_region(recommend_data)
                
                # ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚°
                available_cols = [col for col in self.norm_cols if col in recommend_data.columns]
                self.centroids = calculate_centroids(grouped_data, available_cols, method="median")
                
                print(f"ğŸ“Š ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚° ì™„ë£Œ: {len(self.centroids)}ê°œ")
            except Exception as e:
                print(f"âš ï¸ ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
                
                # ë¹ˆ ì„¼íŠ¸ë¡œì´ë“œ ìƒì„±
                self.centroids = pd.DataFrame(columns=["usage_type", "region"] + self.norm_cols)
    
    def recommend_by_query(self, 
                          query: str, 
                          algorithm: RecommendationAlgorithm = RecommendationAlgorithm.COSINE_SIMILARITY,
                          top_k: int = 10,
                          region: Optional[str] = None) -> RecommendationResponse:
        """ì£¼ì†Œ ê¸°ë°˜ ì¶”ì²œ"""
        if not query:
            return {"query": query, "timestamp": datetime.now(), "algorithm": algorithm, "count": 0, "items": []}
        
        # ì£¼ì†Œ ê²€ìƒ‰
        gas_df = self.data["gas_station"]
        filtered_df = gas_df[gas_df["ì£¼ì†Œ"].astype(str).str.contains(query, na=False)]
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ í–‰ì •êµ¬ì—­ìœ¼ë¡œ ê²€ìƒ‰
        if filtered_df.empty:
            filtered_df = gas_df[gas_df["í–‰ì •êµ¬ì—­"].astype(str).str.contains(query, na=False)]
        
        # ì—¬ì „íˆ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
        if filtered_df.empty:
            return {"query": query, "timestamp": datetime.now(), "algorithm": algorithm, "count": 0, "items": []}
        
        # ê¶Œì—­ í•„í„°ë§
        if region:
            normalized_region = normalize_region(region)
            filtered_df = filtered_df[filtered_df["ê¶Œì—­"] == normalized_region]
        
        # ì„¼íŠ¸ë¡œì´ë“œì™€ ë¹„êµí•˜ì—¬ ì¶”ì²œ
        if algorithm == RecommendationAlgorithm.POPULARITY:
            recommendations = self.recommend_by_popularity(filtered_df, top_k)
        elif algorithm == RecommendationAlgorithm.COLLABORATIVE:
            recommendations = self.recommend_by_collaborative_filtering(filtered_df, top_k)
        elif algorithm == RecommendationAlgorithm.PEARSON_CORRELATION:
            recommendations = self.recommend_by_pearson_correlation(filtered_df, top_k)
        elif algorithm == RecommendationAlgorithm.EUCLIDEAN_DISTANCE:
            recommendations = self.recommend_by_euclidean_distance(filtered_df, top_k)
        else:  # ê¸°ë³¸ê°’: ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            recommendations = self.recommend_by_cosine_similarity(filtered_df, top_k)
        
        # ê²°ê³¼ í˜•ì‹í™”
        return {
            "query": query,
            "timestamp": datetime.now(),
            "algorithm": algorithm,
            "count": len(recommendations),
            "items": recommendations
        }
    
    def recommend_by_popularity(self, df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            # ëŒ€ë¶„ë¥˜ ë¹ˆë„ìˆ˜ ê³„ì‚° (ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv íŒŒì¼ í™œìš©)
            recommend_df = self.data["recommend_result"]
            usage_type_counts = recommend_df["ëŒ€ë¶„ë¥˜"].value_counts().reset_index()
            usage_type_counts.columns = ["usage_type", "count"]
            
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_usage_types = usage_type_counts.head(top_k)
            
            # ê²°ê³¼ í˜•ì‹í™”
            recommendations = []
            
            for i, (_, row) in enumerate(top_usage_types.iterrows()):
                usage_type = row["usage_type"]
                count = row["count"]
                
                # ì²« ë²ˆì§¸ ì£¼ì†Œ ì‚¬ìš©
                if len(df) > 0:
                    address_row = df.iloc[0]
                    address = address_row.get("ì£¼ì†Œ", "")
                    admin_region = address_row.get("í–‰ì •êµ¬ì—­", "")
                    population = float(address_row.get("ì¸êµ¬[ëª…]", 0))
                    business_density = float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0))
                    
                    recommendations.append({
                        "address": address,
                        "admin_region": admin_region,
                        "usage_type": usage_type,
                        "score": float(count / usage_type_counts["count"].max()),
                        "rank": i + 1,
                        "population": population,
                        "business_density": business_density,
                        "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                        "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                        "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                        "station_status": address_row.get("ìƒíƒœ", ""),
                        "note": address_row.get("ë¹„ê³ ", "")
                    })
            
            return recommendations
        
        except Exception as e:
            print(f"âš ï¸ ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def recommend_by_cosine_similarity(self, df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            if len(df) == 0 or len(self.centroids) == 0:
                return []
            
            # ì²« ë²ˆì§¸ ì£¼ì†Œì˜ ë²¡í„° ì¶”ì¶œ
            address_row = df.iloc[0]
            
            # í•„ìš”í•œ ë²¡í„° í™•ì¸
            available_norm_cols = [col for col in self.norm_cols if col in self.centroids.columns]
            
            if not available_norm_cols:
                return []
            
            # ì£¼ì†Œ ë²¡í„° ìƒì„±
            address_vector = np.array([address_row.get(col, 0) for col in available_norm_cols]).reshape(1, -1)
            
            # ì„¼íŠ¸ë¡œì´ë“œ ë²¡í„° ìƒì„±
            centroids_vectors = self.centroids[available_norm_cols].values
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = cosine_similarity(address_vector, centroids_vectors)[0]
            
            # ìœ ì‚¬ë„ì™€ ì„¼íŠ¸ë¡œì´ë“œ ì •ë³´ ê²°í•©
            similarity_df = self.centroids.copy()
            similarity_df["similarity"] = similarities
            
            # ìœ ì‚¬ë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            similarity_df = similarity_df.sort_values("similarity", ascending=False)
            
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_centroids = similarity_df.head(top_k)
            
            # ê²°ê³¼ í˜•ì‹í™”
            recommendations = []
            
            for i, (_, centroid) in enumerate(top_centroids.iterrows()):
                recommendations.append({
                    "address": address_row.get("ì£¼ì†Œ", ""),
                    "admin_region": address_row.get("í–‰ì •êµ¬ì—­", ""),
                    "usage_type": centroid.get("usage_type", ""),
                    "score": float(centroid.get("similarity", 0)),
                    "rank": i + 1,
                    "population": float(address_row.get("ì¸êµ¬[ëª…]", 0)),
                    "business_density": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0)),
                    "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                    "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                    "traffic_norm": float(centroid.get("êµí†µëŸ‰_norm", 0)),
                    "tourism_norm": float(centroid.get("ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)_norm", 0)),
                    "land_price_norm": float(centroid.get("ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)_norm", 0)),
                    "similarity": float(centroid.get("similarity", 0)),
                    "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                    "station_status": address_row.get("ìƒíƒœ", ""),
                    "note": address_row.get("ë¹„ê³ ", "")
                })
            
            return recommendations
        
        except Exception as e:
            print(f"âš ï¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def recommend_by_euclidean_distance(self, df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            if len(df) == 0 or len(self.centroids) == 0:
                return []
            
            # ì²« ë²ˆì§¸ ì£¼ì†Œì˜ ë²¡í„° ì¶”ì¶œ
            address_row = df.iloc[0]
            
            # í•„ìš”í•œ ë²¡í„° í™•ì¸
            available_norm_cols = [col for col in self.norm_cols if col in self.centroids.columns]
            
            if not available_norm_cols:
                return []
            
            # ì£¼ì†Œ ë²¡í„° ìƒì„±
            address_vector = np.array([address_row.get(col, 0) for col in available_norm_cols])
            
            # ì„¼íŠ¸ë¡œì´ë“œì™€ ê±°ë¦¬ ê³„ì‚°
            distances = []
            
            for _, centroid in self.centroids.iterrows():
                # ì„¼íŠ¸ë¡œì´ë“œ ë²¡í„° ìƒì„±
                centroid_vector = np.array([centroid.get(col, 0) for col in available_norm_cols])
                
                # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
                try:
                    distance = euclidean(address_vector, centroid_vector)
                except:
                    distance = float('inf')
                
                distances.append({
                    "usage_type": centroid.get("usage_type", ""),
                    "region": centroid.get("region", ""),
                    "distance": distance,
                    **{col: centroid.get(col, 0) for col in available_norm_cols}
                })
            
            # ê±°ë¦¬ ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
            sorted_distances = sorted(distances, key=lambda x: x["distance"])
            
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_centroids = sorted_distances[:top_k]
            
            # ê²°ê³¼ í˜•ì‹í™”
            recommendations = []
            
            for i, centroid in enumerate(top_centroids):
                # ê±°ë¦¬ ì ìˆ˜ ë³€í™˜ (0~1, ê°€ê¹Œìš¸ìˆ˜ë¡ 1)
                max_distance = sorted_distances[-1]["distance"] if len(sorted_distances) > 0 else 1
                score = 1 - (centroid["distance"] / max_distance if max_distance > 0 else 0)
                
                recommendations.append({
                    "address": address_row.get("ì£¼ì†Œ", ""),
                    "admin_region": address_row.get("í–‰ì •êµ¬ì—­", ""),
                    "usage_type": centroid.get("usage_type", ""),
                    "score": float(score),
                    "rank": i + 1,
                    "population": float(address_row.get("ì¸êµ¬[ëª…]", 0)),
                    "business_density": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0)),
                    "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                    "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                    "traffic_norm": float(centroid.get("êµí†µëŸ‰_norm", 0)),
                    "tourism_norm": float(centroid.get("ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)_norm", 0)),
                    "land_price_norm": float(centroid.get("ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)_norm", 0)),
                    "distance": float(centroid.get("distance", 0)),
                    "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                    "station_status": address_row.get("ìƒíƒœ", ""),
                    "note": address_row.get("ë¹„ê³ ", "")
                })
            
            return recommendations
        
        except Exception as e:
            print(f"âš ï¸ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def recommend_by_pearson_correlation(self, df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            if len(df) == 0 or len(self.centroids) == 0:
                return []
            
            # ì²« ë²ˆì§¸ ì£¼ì†Œì˜ ë²¡í„° ì¶”ì¶œ
            address_row = df.iloc[0]
            
            # í•„ìš”í•œ ë²¡í„° í™•ì¸
            available_norm_cols = [col for col in self.norm_cols if col in self.centroids.columns]
            
            if not available_norm_cols:
                return []
            
            # ì£¼ì†Œ ë²¡í„° ìƒì„±
            address_vector = np.array([address_row.get(col, 0) for col in available_norm_cols])
            
            # ì„¼íŠ¸ë¡œì´ë“œì™€ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            correlations = []
            
            for _, centroid in self.centroids.iterrows():
                # ì„¼íŠ¸ë¡œì´ë“œ ë²¡í„° ìƒì„±
                centroid_vector = np.array([centroid.get(col, 0) for col in available_norm_cols])
                
                # í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
                try:
                    correlation, _ = pearsonr(address_vector, centroid_vector)
                    if math.isnan(correlation):
                        correlation = 0
                except:
                    correlation = 0
                
                correlations.append({
                    "usage_type": centroid.get("usage_type", ""),
                    "region": centroid.get("region", ""),
                    "correlation": correlation,
                    **{col: centroid.get(col, 0) for col in available_norm_cols}
                })
            
            # ìƒê´€ê³„ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            sorted_correlations = sorted(correlations, key=lambda x: x["correlation"], reverse=True)
            
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_centroids = sorted_correlations[:top_k]
            
            # ê²°ê³¼ í˜•ì‹í™”
            recommendations = []
            
            for i, centroid in enumerate(top_centroids):
                # ìƒê´€ê³„ìˆ˜ ì ìˆ˜ ë³€í™˜ (-1~1 -> 0~1)
                score = (centroid["correlation"] + 1) / 2
                
                recommendations.append({
                    "address": address_row.get("ì£¼ì†Œ", ""),
                    "admin_region": address_row.get("í–‰ì •êµ¬ì—­", ""),
                    "usage_type": centroid.get("usage_type", ""),
                    "score": float(score),
                    "rank": i + 1,
                    "population": float(address_row.get("ì¸êµ¬[ëª…]", 0)),
                    "business_density": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0)),
                    "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                    "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                    "traffic_norm": float(centroid.get("êµí†µëŸ‰_norm", 0)),
                    "tourism_norm": float(centroid.get("ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)_norm", 0)),
                    "land_price_norm": float(centroid.get("ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)_norm", 0)),
                    "similarity": float(centroid.get("correlation", 0)),
                    "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                    "station_status": address_row.get("ìƒíƒœ", ""),
                    "note": address_row.get("ë¹„ê³ ", "")
                })
            
            return recommendations
        
        except Exception as e:
            print(f"âš ï¸ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def recommend_by_collaborative_filtering(self, df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            # ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv íŒŒì¼ í™œìš©
            recommend_df = self.data["recommend_result"]
            
            if len(df) == 0 or len(recommend_df) == 0:
                return []
            
            # ì²« ë²ˆì§¸ ì£¼ì†Œ ì •ë³´
            address_row = df.iloc[0]
            address_region = address_row.get("ê¶Œì—­", "")
            
            # ì£¼ì†Œì˜ ê¶Œì—­ê³¼ ì¼ì¹˜í•˜ëŠ” í–‰ ì„ íƒ
            region_recommend = recommend_df[recommend_df["ê¶Œì—­"] == address_region]
            
            if len(region_recommend) == 0:
                # ê¶Œì—­ì´ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©
                region_recommend = recommend_df
            
            # ëŒ€ë¶„ë¥˜ë³„ í‰ê·  ì¶”ì²œ ì ìˆ˜ ê³„ì‚°
            usage_type_scores = region_recommend.groupby("ëŒ€ë¶„ë¥˜")["ì¶”ì²œ_ëŒ€ë¶„ë¥˜"].count().reset_index()
            usage_type_scores.columns = ["usage_type", "count"]
            
            # ì ìˆ˜ ì •ê·œí™”
            total_count = usage_type_scores["count"].sum()
            usage_type_scores["score"] = usage_type_scores["count"] / total_count if total_count > 0 else 0
            
            # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            usage_type_scores = usage_type_scores.sort_values("score", ascending=False)
            
            # ìƒìœ„ top_kê°œ ì„ íƒ
            top_usage_types = usage_type_scores.head(top_k)
            
            # ê²°ê³¼ í˜•ì‹í™”
            recommendations = []
            
            for i, (_, row) in enumerate(top_usage_types.iterrows()):
                usage_type = row["usage_type"]
                score = row["score"]
                
                recommendations.append({
                    "address": address_row.get("ì£¼ì†Œ", ""),
                    "admin_region": address_row.get("í–‰ì •êµ¬ì—­", ""),
                    "usage_type": usage_type,
                    "score": float(score),
                    "rank": i + 1,
                    "population": float(address_row.get("ì¸êµ¬[ëª…]", 0)),
                    "business_density": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜", 0)),
                    "population_norm": float(address_row.get("ì¸êµ¬[ëª…]_norm", 0)),
                    "business_density_norm": float(address_row.get("ì¸êµ¬ì²œëª…ë‹¹ì‚¬ì—…ì²´ìˆ˜_norm", 0)),
                    "station_name": address_row.get("ìƒí˜¸ëª…", ""),
                    "station_status": address_row.get("ìƒíƒœ", ""),
                    "note": address_row.get("ë¹„ê³ ", "")
                })
            
            return recommendations
        
        except Exception as e:
            print(f"âš ï¸ í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}")
            return []

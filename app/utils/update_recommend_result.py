# ğŸ“„ app/utils/update_recommend_result.py

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os


def update_recommend_result(train_path: str, centroid_path: str, output_path: str):
    """
    train.csvì˜ ê° í–‰ì— ëŒ€í•´ ëŒ€ë¶„ë¥˜_ê¶Œì—­ë³„_ì„¼í„°ë¡œì´ë“œ.csv ê¸°ì¤€ìœ¼ë¡œ
    ê°€ì¥ ìœ ì‚¬í•œ ëŒ€ë¶„ë¥˜ë¥¼ ê³„ì‚°í•´ ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csvë¡œ ì €ì¥
    """
    print("ğŸš€ ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv ê°±ì‹  ì‹œì‘")

    # --- ë°ì´í„° ë¡œë“œ ---
    train_df = pd.read_csv(train_path)
    centroid_df = pd.read_csv(centroid_path)

    # --- ê³µí†µ í”¼ì²˜ ---
    feature_cols = ["ì¸êµ¬[ëª…]", "êµí†µëŸ‰(AADT)", "ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)", "ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)"]
    norm_cols = [f"{col}_norm" for col in feature_cols]

    # --- train ì •ê·œí™” (Z-score) ---
    for col in feature_cols:
        mean = train_df[col].mean()
        std = train_df[col].std()
        if std == 0 or pd.isna(std):
            train_df[f"{col}_norm"] = 0
        else:
            train_df[f"{col}_norm"] = (train_df[col] - mean) / std

    # --- ì¶”ì²œ ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ---
    results = []

    # --- ê° í–‰ë³„ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ---
    for _, row in train_df.iterrows():
        region = str(row["ê´€í• ì£¼ì†Œ"]) if "ê´€í• ì£¼ì†Œ" in row else None
        address_vec = np.array([row[col] for col in norm_cols]).reshape(1, -1)

        # í•´ë‹¹ ê¶Œì—­ì˜ ì„¼í„°ë¡œì´ë“œë§Œ í•„í„°ë§
        region_centroids = centroid_df[centroid_df["ê¶Œì—­"] == region]

        if len(region_centroids) == 0:
            # í•´ë‹¹ ê¶Œì—­ì´ ì—†ìœ¼ë©´ ì „ì²´ ì¤‘ì—ì„œ íƒìƒ‰
            region_centroids = centroid_df.copy()

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        centroid_vecs = region_centroids[norm_cols].fillna(0).to_numpy()
        sims = cosine_similarity(address_vec, centroid_vecs)[0]

        # ìµœê³  ìœ ì‚¬ë„ ëŒ€ë¶„ë¥˜ ì„ íƒ
        best_idx = int(np.argmax(sims))
        best_usage = region_centroids.iloc[best_idx]["ëŒ€ë¶„ë¥˜"]
        best_sim = sims[best_idx]

        results.append({
            "ëŒ€ë¶„ë¥˜": row["ëŒ€ë¶„ë¥˜"],
            "ì§€ë²ˆì£¼ì†Œ (ì/ë©´/ë™)": row["ì§€ë²ˆì£¼ì†Œ (ì/ë©´/ë™)"],
            "ê´€í• ì£¼ì†Œ": row["ê´€í• ì£¼ì†Œ"],
            "ì¸êµ¬[ëª…]": row["ì¸êµ¬[ëª…]"],
            "êµí†µëŸ‰(AADT)": row["êµí†µëŸ‰(AADT)"],
            "ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)": row["ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)"],
            "ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)": row["ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)"],
            "ì¶”ì²œ_ëŒ€ë¶„ë¥˜": best_usage,
            "ì¶”ì²œ_ìœ ì‚¬ë„": best_sim
        })

    result_df = pd.DataFrame(results)

    # --- ì €ì¥ ---
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    result_df.to_csv(output_path, index=False, encoding="utf-8-sig")

    print(f"âœ… ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv ê°±ì‹  ì™„ë£Œ: {output_path}")
    print(f"ì´ {len(result_df)}ê°œ í–‰ ì²˜ë¦¬ ì™„ë£Œ")


if __name__ == "__main__":
    update_recommend_result(
        train_path="data/train.csv",
        centroid_path="data/ëŒ€ë¶„ë¥˜_ì„¼í„°ë¡œì´ë“œ.csv",
        output_path="data/ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv"
    )

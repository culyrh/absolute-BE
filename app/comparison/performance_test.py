"""
ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python -m app.comparison.performance_test
    
í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” data/test_data.csvì— ìˆ˜ë™ìœ¼ë¡œ ì¤€ë¹„ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from typing import Dict, List
from datetime import datetime
import time
from pathlib import Path

from app.utils.data_loader import load_all_data
from app.utils.preprocessing import normalize_features
from app.comparison.algorithms.cosine_similarity import CosineSimilarityAlgorithm
from app.comparison.algorithms.euclidean_distance import EuclideanDistanceAlgorithm
from app.comparison.algorithms.pearson_correlation import PearsonCorrelationAlgorithm
from app.comparison.algorithms.popularity import PopularityAlgorithm
from app.comparison.algorithms.collaborative import CollaborativeAlgorithm
from app.comparison.algorithms.ahp_topsis import AHPTopsisAlgorithm


class PerformanceTest:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.data = None
        self.train_data = None
        self.test_data = None
        self.centroids = None
        self.feature_cols = ["ì¸êµ¬[ëª…]", "êµí†µëŸ‰", "ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)", "ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)", "ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)"]
        self.norm_cols = [f"{col}_norm" for col in self.feature_cols]
        self.results = {}
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ëª¨ë“  ë°ì´í„° ë¡œë“œ
        self.data = load_all_data()
        
        # Train ë°ì´í„°: ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv
        self.train_data = self.data["recommend_result"]
        print(f"âœ… Train ë°ì´í„° ë¡œë“œ: {len(self.train_data)}ê°œ")
        
        # ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„°
        self.centroids = self.data["centroid"]
        
    def load_test_data(self, test_file_path: str = "data/test_data.csv"):
        """
        ìˆ˜ë™ìœ¼ë¡œ ì¤€ë¹„ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ (ì›ë³¸ í˜•ì‹)
        
        Args:
            test_file_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            
        í…ŒìŠ¤íŠ¸ ë°ì´í„° í˜•ì‹:
        - í•„ìˆ˜ ì»¬ëŸ¼: ëŒ€ë¶„ë¥˜, ì¸êµ¬[ëª…], êµí†µëŸ‰(AADT), ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜), ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)
        - ì„ íƒ ì»¬ëŸ¼: ì§€ë²ˆì£¼ì†Œ, ê´€í• ì£¼ì†Œ, ìœ„ë„, ê²½ë„
        """
        print(f"\nğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘: {test_file_path}")
        
        try:
            self.test_data = pd.read_csv(test_file_path, encoding="utf-8-sig")
            print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.test_data)}ê°œ")
            
            # êµí†µëŸ‰(AADT) ì»¬ëŸ¼ëª… í†µì¼
            if "êµí†µëŸ‰(AADT)" in self.test_data.columns:
                self.test_data.rename(columns={"êµí†µëŸ‰(AADT)": "êµí†µëŸ‰"}, inplace=True)
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_cols = ["ëŒ€ë¶„ë¥˜"] + self.feature_cols
            missing_cols = [col for col in required_cols if col not in self.test_data.columns]
            
            if missing_cols:
                print(f"âš ï¸ ê²½ê³ : ë‹¤ìŒ ì»¬ëŸ¼ì´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
            
            # ì •ê·œí™” ìˆ˜í–‰ (train ë°ì´í„°ì™€ ë™ì¼í•œ ë°©ì‹)
            available_cols = [col for col in self.feature_cols if col in self.test_data.columns]
            self.test_data = normalize_features(self.test_data, available_cols)
            
            # ëŒ€ë¶„ë¥˜ ë¶„í¬ ì¶œë ¥
            if "ëŒ€ë¶„ë¥˜" in self.test_data.columns:
                print(f"   - ëŒ€ë¶„ë¥˜ ì¢…ë¥˜: {self.test_data['ëŒ€ë¶„ë¥˜'].nunique()}ê°œ")
                print(f"   - ëŒ€ë¶„ë¥˜ ë¶„í¬:\n{self.test_data['ëŒ€ë¶„ë¥˜'].value_counts()}")
            
            return self.test_data
            
        except FileNotFoundError:
            print(f"âŒ ì˜¤ë¥˜: í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_file_path}")
            print("   í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ data/test_data.csvì— ìˆ˜ë™ìœ¼ë¡œ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
            print("\n   í•„ìˆ˜ í˜•ì‹:")
            print("   ëŒ€ë¶„ë¥˜,ì§€ë²ˆì£¼ì†Œ (ì/ë©´/ë™),ê´€í• ì£¼ì†Œ,ì¸êµ¬[ëª…],êµí†µëŸ‰(AADT),ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜),ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)")
            raise
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def run_algorithm_test(self, algorithm, algorithm_name: str) -> Dict:
        """ë‹¨ì¼ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\nâ±ï¸  {algorithm_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        results = {
            "algorithm": algorithm_name,
            "top1_correct": 0,
            "top3_correct": 0,
            "top5_correct": 0,
            "total": len(self.test_data),
            "execution_times": [],
            "region_accuracy": {},
            "usage_type_accuracy": {}
        }
        
        for idx, row in self.test_data.iterrows():
            # ì •ë‹µ
            true_label = row["ëŒ€ë¶„ë¥˜"]
            region = row.get("ê¶Œì—­", "")
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            test_df = pd.DataFrame([row])
            
            # ì¶”ì²œ ì‹¤í–‰
            start_time = time.time()
            try:
                recommendations = algorithm.recommend(test_df, top_k=5)
                execution_time = time.time() - start_time
                results["execution_times"].append(execution_time)
                
                if len(recommendations) > 0:
                    # Top-1 ì •í™•ë„
                    if recommendations[0]["usage_type"] == true_label:
                        results["top1_correct"] += 1
                    
                    # Top-3 ì •í™•ë„
                    top3_types = [r["usage_type"] for r in recommendations[:3]]
                    if true_label in top3_types:
                        results["top3_correct"] += 1
                    
                    # Top-5 ì •í™•ë„
                    top5_types = [r["usage_type"] for r in recommendations[:5]]
                    if true_label in top5_types:
                        results["top5_correct"] += 1
                    
                    # ê¶Œì—­ë³„ ì •í™•ë„
                    if region:
                        if region not in results["region_accuracy"]:
                            results["region_accuracy"][region] = {"correct": 0, "total": 0}
                        
                        results["region_accuracy"][region]["total"] += 1
                        if recommendations[0]["usage_type"] == true_label:
                            results["region_accuracy"][region]["correct"] += 1
                    
                    # ëŒ€ë¶„ë¥˜ë³„ ì •í™•ë„
                    if true_label not in results["usage_type_accuracy"]:
                        results["usage_type_accuracy"][true_label] = {"correct": 0, "total": 0}
                    
                    results["usage_type_accuracy"][true_label]["total"] += 1
                    if recommendations[0]["usage_type"] == true_label:
                        results["usage_type_accuracy"][true_label]["correct"] += 1
                        
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜ (ì¸ë±ìŠ¤ {idx}): {str(e)}")
                results["execution_times"].append(0)
        
        # ì •í™•ë„ ê³„ì‚°
        results["top1_accuracy"] = (results["top1_correct"] / results["total"]) * 100 if results["total"] > 0 else 0
        results["top3_accuracy"] = (results["top3_correct"] / results["total"]) * 100 if results["total"] > 0 else 0
        results["top5_accuracy"] = (results["top5_correct"] / results["total"]) * 100 if results["total"] > 0 else 0
        results["avg_execution_time"] = np.mean(results["execution_times"]) * 1000 if results["execution_times"] else 0  # ms
        
        print(f"   âœ… Top-1 ì •í™•ë„: {results['top1_accuracy']:.2f}%")
        print(f"   âœ… Top-3 ì •í™•ë„: {results['top3_accuracy']:.2f}%")
        print(f"   âœ… Top-5 ì •í™•ë„: {results['top5_accuracy']:.2f}%")
        print(f"   âš¡ í‰ê·  ì‹¤í–‰ì‹œê°„: {results['avg_execution_time']:.2f} ms")
        
        return results
    
    def run_all_tests(self):
        """ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸"""
        print("\n" + "="*70)
        print("ğŸš€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*70)
        
        # ì•Œê³ ë¦¬ì¦˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        algorithms = {
            "ì½”ì‚¬ì¸ ìœ ì‚¬ë„": CosineSimilarityAlgorithm(
                self.centroids, self.norm_cols
            ),
            "ìœ í´ë¦¬ë“œ ê±°ë¦¬": EuclideanDistanceAlgorithm(
                self.centroids, self.norm_cols
            ),
            "í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜": PearsonCorrelationAlgorithm(
                self.centroids, self.norm_cols
            ),
            "ì¸ê¸°ë„ ê¸°ë°˜": PopularityAlgorithm(
                self.centroids, self.norm_cols, self.train_data
            ),
            "í˜‘ì—… í•„í„°ë§": CollaborativeAlgorithm(
                self.centroids, self.norm_cols, self.train_data
            ),
            "AHP-TOPSIS": AHPTopsisAlgorithm(
                self.centroids, self.norm_cols, self.train_data
            ),
        }
        
        # ê° ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸
        for name, algorithm in algorithms.items():
            result = self.run_algorithm_test(algorithm, name)
            self.results[name] = result
        
        # ê²°ê³¼ ì¶œë ¥
        self.print_results()
        
        # ê²°ê³¼ ì €ì¥
        self.save_results()
    
    def print_results(self):
        """ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*70)
        print("ğŸ“Š ì „ì²´ ì •í™•ë„ ë¹„êµ")
        print("="*70 + "\n")
        
        # í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
        print(f"{'ì•Œê³ ë¦¬ì¦˜':<20} {'Top-1':<10} {'Top-3':<10} {'Top-5':<10} {'ì‹¤í–‰ì‹œê°„(ms)':<15}")
        print("-" * 70)
        
        for name, result in self.results.items():
            print(f"{name:<20} {result['top1_accuracy']:>6.2f}%  {result['top3_accuracy']:>6.2f}%  "
                  f"{result['top5_accuracy']:>6.2f}%  {result['avg_execution_time']:>10.2f}")
        
        print("\n" + "="*70)
        
        # ìµœê³  ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜
        if self.results:
            best_algo = max(self.results.items(), key=lambda x: x[1]["top1_accuracy"])
            print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜: {best_algo[0]}")
            print(f"   Top-1 ì •í™•ë„: {best_algo[1]['top1_accuracy']:.2f}%")
        print("="*70 + "\n")
    
    def save_results(self):
        """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        output_dir = Path("test_results")
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì „ì²´ ê²°ê³¼
        summary_data = []
        for name, result in self.results.items():
            summary_data.append({
                "ì•Œê³ ë¦¬ì¦˜": name,
                "Top-1 ì •í™•ë„(%)": result["top1_accuracy"],
                "Top-3 ì •í™•ë„(%)": result["top3_accuracy"],
                "Top-5 ì •í™•ë„(%)": result["top5_accuracy"],
                "í‰ê·  ì‹¤í–‰ì‹œê°„(ms)": result["avg_execution_time"],
                "í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜": result["total"]
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_file = output_dir / f"summary_{timestamp}.csv"
        summary_df.to_csv(summary_file, index=False, encoding="utf-8-sig")
        print(f"ğŸ’¾ ì „ì²´ ê²°ê³¼ ì €ì¥: {summary_file}")
        
        # ê¶Œì—­ë³„ ê²°ê³¼
        for algo_name, result in self.results.items():
            if result["region_accuracy"]:
                region_data = []
                for region, acc in result["region_accuracy"].items():
                    region_data.append({
                        "ê¶Œì—­": region,
                        "ì •í™•ë„(%)": (acc["correct"] / acc["total"]) * 100 if acc["total"] > 0 else 0,
                        "ì •í™• ìˆ˜": acc["correct"],
                        "ì „ì²´ ìˆ˜": acc["total"]
                    })
                
                region_df = pd.DataFrame(region_data)
                region_file = output_dir / f"region_{algo_name.replace(' ', '_')}_{timestamp}.csv"
                region_df.to_csv(region_file, index=False, encoding="utf-8-sig")
        
        print(f"ğŸ’¾ ê¶Œì—­ë³„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
        
        # ëŒ€ë¶„ë¥˜ë³„ ê²°ê³¼
        for algo_name, result in self.results.items():
            usage_data = []
            for usage_type, acc in result["usage_type_accuracy"].items():
                usage_data.append({
                    "ëŒ€ë¶„ë¥˜": usage_type,
                    "ì •í™•ë„(%)": (acc["correct"] / acc["total"]) * 100 if acc["total"] > 0 else 0,
                    "ì •í™• ìˆ˜": acc["correct"],
                    "ì „ì²´ ìˆ˜": acc["total"]
                })
            
            usage_df = pd.DataFrame(usage_data)
            usage_file = output_dir / f"usage_type_{algo_name.replace(' ', '_')}_{timestamp}.csv"
            usage_df.to_csv(usage_file, index=False, encoding="utf-8-sig")
        
        print(f"ğŸ’¾ ëŒ€ë¶„ë¥˜ë³„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ\n")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    test = PerformanceTest()
    
    # 1. ë°ì´í„° ë¡œë“œ
    test.load_data()
    
    # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ (ìˆ˜ë™ìœ¼ë¡œ ì¤€ë¹„ëœ ë°ì´í„°)
    try:
        test.load_test_data("data/test_data.csv")
    except Exception as e:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        print("í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ data/test_data.csvì— ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
        print("\ní•„ìˆ˜ í˜•ì‹:")
        print("ëŒ€ë¶„ë¥˜,ì§€ë²ˆì£¼ì†Œ (ì/ë©´/ë™),ê´€í• ì£¼ì†Œ,ì¸êµ¬[ëª…],êµí†µëŸ‰(AADT),ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜),ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)")
        return
    
    # 3. ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸
    test.run_all_tests()
    
    print("\nâœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
"""
ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python -m app.comparison.performance_test
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
from datetime import datetime
import time
from pathlib import Path

from app.utils.data_loader import load_all_data
from app.utils.preprocessing import (
    preprocess_gas_station_data, merge_with_stats, normalize_features
)
from app.comparison.algorithms.cosine_similarity import CosineSimilarityAlgorithm
from app.comparison.algorithms.euclidean_distance import EuclideanDistanceAlgorithm
from app.comparison.algorithms.pearson_correlation import PearsonCorrelationAlgorithm
from app.comparison.algorithms.popularity import PopularityAlgorithm
from app.comparison.algorithms.collaborative import CollaborativeAlgorithm
from app.comparison.algorithms.ahp_topsis import AHPTopsisAlgorithm


class PerformanceTest:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.data = None
        self.train_data = None
        self.test_data = None
        self.centroids = None
        self.norm_cols = None
        self.results = {}
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ëª¨ë“  ë°ì´í„° ë¡œë“œ
        self.data = load_all_data()
        
        # Train ë°ì´í„°: ì¶”ì²œê²°ê³¼_í–‰ë‹¨ìœ„.csv (1,440ê°œ)
        self.train_data = self.data["recommend_result"]
        print(f"âœ… Train ë°ì´í„° ë¡œë“œ: {len(self.train_data)}ê°œ")
        
        # ì„¼íŠ¸ë¡œì´ë“œ ë°ì´í„°
        self.centroids = self.data["centroid"]
        
        # ì •ê·œí™” ì»¬ëŸ¼
        feature_cols = ["ì¸êµ¬[ëª…]", "êµí†µëŸ‰", "ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)", "ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)", "ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)"]
        self.norm_cols = [f"{col}_norm" for col in feature_cols]
        
    def generate_test_data(self) -> pd.DataFrame:
        """
        ì¦ê°• í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        
        ë°©ë²•: ëŒ€ë¶„ë¥˜ë³„ ê¶Œì—­ë‹¹ 3ê°œì”© ìƒì„±
        - ê° ëŒ€ë¶„ë¥˜ì˜ ê¶Œì—­ë³„ ì¤‘ìœ„ê°’ ê¸°ì¤€
        - ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€í•˜ì—¬ 3ê°œ ìƒ˜í”Œ ìƒì„±
        """
        print("\nğŸ”¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì¤‘...")
        
        # ëŒ€ë¶„ë¥˜ ëª©ë¡
        usage_types = self.train_data["ëŒ€ë¶„ë¥˜"].unique()
        
        # ê¶Œì—­ ëª©ë¡ (17ê°œ)
        regions = self.train_data["ê¶Œì—­"].unique() if "ê¶Œì—­" in self.train_data.columns else []
        
        if len(regions) == 0:
            regions = [
                "ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°ê´‘ì—­ì‹œ", "ëŒ€êµ¬ê´‘ì—­ì‹œ", "ì¸ì²œê´‘ì—­ì‹œ",
                "ê´‘ì£¼ê´‘ì—­ì‹œ", "ëŒ€ì „ê´‘ì—­ì‹œ", "ìš¸ì‚°ê´‘ì—­ì‹œ", "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
                "ê²½ê¸°ë„", "ê°•ì›íŠ¹ë³„ìì¹˜ë„", "ì¶©ì²­ë¶ë„", "ì¶©ì²­ë‚¨ë„",
                "ì „ë¶íŠ¹ë³„ìì¹˜ë„", "ì „ë¼ë‚¨ë„", "ê²½ìƒë¶ë„", "ê²½ìƒë‚¨ë„", "ì œì£¼íŠ¹ë³„ìì¹˜ë„"
            ]
        
        test_samples = []
        
        for usage_type in usage_types:
            for region in regions:
                # í•´ë‹¹ ëŒ€ë¶„ë¥˜ + ê¶Œì—­ì˜ ë°ì´í„° í•„í„°ë§
                subset = self.train_data[
                    (self.train_data["ëŒ€ë¶„ë¥˜"] == usage_type) &
                    (self.train_data["ê¶Œì—­"] == region)
                ]
                
                if len(subset) > 0:
                    # ì¤‘ìœ„ê°’ ê³„ì‚°
                    available_norm_cols = [col for col in self.norm_cols if col in subset.columns]
                    
                    medians = {}
                    for col in available_norm_cols:
                        medians[col] = subset[col].median()
                    
                    # 3ê°œ ìƒ˜í”Œ ìƒì„± (ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€)
                    for i in range(3):
                        sample = {
                            "ëŒ€ë¶„ë¥˜": usage_type,
                            "ê¶Œì—­": region,
                            "test_id": f"{usage_type}_{region}_{i+1}"
                        }
                        
                        # ê° íŠ¹ì§•ì— ë…¸ì´ì¦ˆ ì¶”ê°€ (Â±10% ë²”ìœ„)
                        for col in available_norm_cols:
                            noise = np.random.uniform(-0.1, 0.1)
                            sample[col] = max(0, min(1, medians[col] + noise))
                        
                        # ì›ë³¸ ì •ë³´ (ì£¼ì†Œ ë“±)
                        if len(subset) > 0:
                            sample_row = subset.iloc[0]
                            sample["ì£¼ì†Œ"] = f"{region} (í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ {i+1})"
                            sample["í–‰ì •êµ¬ì—­"] = sample_row.get("í–‰ì •êµ¬ì—­", region)
                        
                        test_samples.append(sample)
        
        self.test_data = pd.DataFrame(test_samples)
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(self.test_data)}ê°œ")
        print(f"   - ëŒ€ë¶„ë¥˜ ìˆ˜: {len(usage_types)}")
        print(f"   - ê¶Œì—­ ìˆ˜: {len(regions)}")
        print(f"   - ìƒ˜í”Œë‹¹ ê°œìˆ˜: 3ê°œ")
        
        return self.test_data
    
    def run_algorithm_test(self, algorithm, algorithm_name: str) -> Dict:
        """ë‹¨ì¼ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\nâ±ï¸  {algorithm_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        results = {
            "algorithm": algorithm_name,
            "top1_correct": 0,
            "top3_correct": 0,
            "top5_correct": 0,
            "total": len(self.test_data),
            "execution_times": [],
            "region_accuracy": {},
            "usage_type_accuracy": {}
        }
        
        for idx, row in self.test_data.iterrows():
            # ì •ë‹µ
            true_label = row["ëŒ€ë¶„ë¥˜"]
            region = row["ê¶Œì—­"]
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            test_df = pd.DataFrame([row])
            
            # ì¶”ì²œ ì‹¤í–‰
            start_time = time.time()
            try:
                recommendations = algorithm.recommend(test_df, top_k=5)
                execution_time = time.time() - start_time
                results["execution_times"].append(execution_time)
                
                if len(recommendations) > 0:
                    # Top-1 ì •í™•ë„
                    if recommendations[0]["usage_type"] == true_label:
                        results["top1_correct"] += 1
                    
                    # Top-3 ì •í™•ë„
                    top3_types = [r["usage_type"] for r in recommendations[:3]]
                    if true_label in top3_types:
                        results["top3_correct"] += 1
                    
                    # Top-5 ì •í™•ë„
                    top5_types = [r["usage_type"] for r in recommendations[:5]]
                    if true_label in top5_types:
                        results["top5_correct"] += 1
                    
                    # ê¶Œì—­ë³„ ì •í™•ë„
                    if region not in results["region_accuracy"]:
                        results["region_accuracy"][region] = {"correct": 0, "total": 0}
                    
                    results["region_accuracy"][region]["total"] += 1
                    if recommendations[0]["usage_type"] == true_label:
                        results["region_accuracy"][region]["correct"] += 1
                    
                    # ëŒ€ë¶„ë¥˜ë³„ ì •í™•ë„
                    if true_label not in results["usage_type_accuracy"]:
                        results["usage_type_accuracy"][true_label] = {"correct": 0, "total": 0}
                    
                    results["usage_type_accuracy"][true_label]["total"] += 1
                    if recommendations[0]["usage_type"] == true_label:
                        results["usage_type_accuracy"][true_label]["correct"] += 1
                        
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {str(e)}")
                results["execution_times"].append(0)
        
        # ì •í™•ë„ ê³„ì‚°
        results["top1_accuracy"] = (results["top1_correct"] / results["total"]) * 100
        results["top3_accuracy"] = (results["top3_correct"] / results["total"]) * 100
        results["top5_accuracy"] = (results["top5_correct"] / results["total"]) * 100
        results["avg_execution_time"] = np.mean(results["execution_times"]) * 1000  # ms
        
        print(f"   âœ… Top-1 ì •í™•ë„: {results['top1_accuracy']:.2f}%")
        print(f"   âœ… Top-3 ì •í™•ë„: {results['top3_accuracy']:.2f}%")
        print(f"   âœ… Top-5 ì •í™•ë„: {results['top5_accuracy']:.2f}%")
        print(f"   âš¡ í‰ê·  ì‹¤í–‰ì‹œê°„: {results['avg_execution_time']:.2f} ms")
        
        return results
    
    def run_all_tests(self):
        """ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸"""
        print("\n" + "="*70)
        print("ğŸš€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*70)
        
        # ì•Œê³ ë¦¬ì¦˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        algorithms = {
            "AHP-TOPSIS": AHPTopsisAlgorithm(
                self.centroids, self.norm_cols, self.train_data
            ),
            "ê¸°ë³¸ CF": CollaborativeAlgorithm(
                self.centroids, self.norm_cols, self.train_data
            ),
            "ì½”ì‚¬ì¸ ìœ ì‚¬ë„ CF": CosineSimilarityAlgorithm(
                self.centroids, self.norm_cols
            ),
            "í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ CF": PearsonCorrelationAlgorithm(
                self.centroids, self.norm_cols
            ),
        }
        
        # ê° ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸
        for name, algorithm in algorithms.items():
            result = self.run_algorithm_test(algorithm, name)
            self.results[name] = result
        
        # ê²°ê³¼ ì¶œë ¥
        self.print_results()
        
        # ê²°ê³¼ ì €ì¥
        self.save_results()
    
    def print_results(self):
        """ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*70)
        print("ğŸ“Š ì „ì²´ ì •í™•ë„ ë¹„êµ")
        print("="*70 + "\n")
        
        # í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
        print(f"{'ì•Œê³ ë¦¬ì¦˜':<20} {'Top-1':<10} {'Top-3':<10} {'Top-5':<10} {'ì‹¤í–‰ì‹œê°„(ms)':<15}")
        print("-" * 70)
        
        for name, result in self.results.items():
            print(f"{name:<20} {result['top1_accuracy']:>6.2f}%  {result['top3_accuracy']:>6.2f}%  "
                  f"{result['top5_accuracy']:>6.2f}%  {result['avg_execution_time']:>10.2f}")
        
        print("\n" + "="*70)
        
        # ìµœê³  ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜
        best_algo = max(self.results.items(), key=lambda x: x[1]["top1_accuracy"])
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜: {best_algo[0]}")
        print(f"   Top-1 ì •í™•ë„: {best_algo[1]['top1_accuracy']:.2f}%")
        print("="*70 + "\n")
    
    def save_results(self):
        """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        output_dir = Path("test_results")
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì „ì²´ ê²°ê³¼
        summary_data = []
        for name, result in self.results.items():
            summary_data.append({
                "ì•Œê³ ë¦¬ì¦˜": name,
                "Top-1 ì •í™•ë„(%)": result["top1_accuracy"],
                "Top-3 ì •í™•ë„(%)": result["top3_accuracy"],
                "Top-5 ì •í™•ë„(%)": result["top5_accuracy"],
                "í‰ê·  ì‹¤í–‰ì‹œê°„(ms)": result["avg_execution_time"],
                "í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜": result["total"]
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_file = output_dir / f"summary_{timestamp}.csv"
        summary_df.to_csv(summary_file, index=False, encoding="utf-8-sig")
        print(f"ğŸ’¾ ì „ì²´ ê²°ê³¼ ì €ì¥: {summary_file}")
        
        # ê¶Œì—­ë³„ ê²°ê³¼
        for algo_name, result in self.results.items():
            region_data = []
            for region, acc in result["region_accuracy"].items():
                region_data.append({
                    "ê¶Œì—­": region,
                    "ì •í™•ë„(%)": (acc["correct"] / acc["total"]) * 100 if acc["total"] > 0 else 0,
                    "ì •í™• ìˆ˜": acc["correct"],
                    "ì „ì²´ ìˆ˜": acc["total"]
                })
            
            region_df = pd.DataFrame(region_data)
            region_file = output_dir / f"region_{algo_name.replace(' ', '_')}_{timestamp}.csv"
            region_df.to_csv(region_file, index=False, encoding="utf-8-sig")
        
        print(f"ğŸ’¾ ê¶Œì—­ë³„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
        
        # ëŒ€ë¶„ë¥˜ë³„ ê²°ê³¼
        for algo_name, result in self.results.items():
            usage_data = []
            for usage_type, acc in result["usage_type_accuracy"].items():
                usage_data.append({
                    "ëŒ€ë¶„ë¥˜": usage_type,
                    "ì •í™•ë„(%)": (acc["correct"] / acc["total"]) * 100 if acc["total"] > 0 else 0,
                    "ì •í™• ìˆ˜": acc["correct"],
                    "ì „ì²´ ìˆ˜": acc["total"]
                })
            
            usage_df = pd.DataFrame(usage_data)
            usage_file = output_dir / f"usage_type_{algo_name.replace(' ', '_')}_{timestamp}.csv"
            usage_df.to_csv(usage_file, index=False, encoding="utf-8-sig")
        
        print(f"ğŸ’¾ ëŒ€ë¶„ë¥˜ë³„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ\n")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    test = PerformanceTest()
    
    # 1. ë°ì´í„° ë¡œë“œ
    test.load_data()
    
    # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test.generate_test_data()
    
    # 3. ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸
    test.run_all_tests()
    
    print("\nâœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
"""
ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ì†ë„ ì¸¡ì •)

ì‚¬ìš©ë²•:
    python -m app.comparison.benchmark
"""

import time
import pandas as pd
from typing import Dict, List

from app.utils.data_loader import load_all_data
from app.utils.preprocessing import preprocess_gas_station_data, merge_with_stats, normalize_features

from app.comparison.algorithms.cosine_similarity import CosineSimilarityAlgorithm
from app.comparison.algorithms.euclidean_distance import EuclideanDistanceAlgorithm
from app.comparison.algorithms.pearson_correlation import PearsonCorrelationAlgorithm
from app.comparison.algorithms.popularity import PopularityAlgorithm
from app.comparison.algorithms.collaborative import CollaborativeAlgorithm
from app.comparison.algorithms.ahp_topsis import AHPTopsisAlgorithm


def load_and_prepare_data():
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
    data = load_all_data()
    
    data["gas_station"] = preprocess_gas_station_data(data["gas_station"])
    data["gas_station"] = merge_with_stats(
        data["gas_station"],
        data["population"],
        data["business"]
    )
    
    feature_cols = ["ì¸êµ¬[ëª…]", "êµí†µëŸ‰", "ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)", "ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)", "ê³µì‹œì§€ê°€(í† ì§€ë‹¨ê°€)"]
    available_cols = [col for col in feature_cols if col in data["gas_station"].columns]
    data["gas_station"] = normalize_features(data["gas_station"], available_cols)
    
    norm_cols = [f"{col}_norm" for col in feature_cols]
    
    return data, norm_cols


def run_benchmark(queries: List[str] = None, iterations: int = 5):
    """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    
    if queries is None:
        queries = ["ì„œìš¸ ê°•ë‚¨êµ¬", "ë¶€ì‚° í•´ìš´ëŒ€êµ¬", "ì „ì£¼ì‹œ"]
    
    # ë°ì´í„° ì¤€ë¹„
    data, norm_cols = load_and_prepare_data()
    centroids = data["centroid"]
    gas_df = data["gas_station"]
    recommend_result = data["recommend_result"]
    
    # ì•Œê³ ë¦¬ì¦˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    algorithms = {
        "ì½”ì‚¬ì¸ ìœ ì‚¬ë„": CosineSimilarityAlgorithm(centroids, norm_cols),
        "ìœ í´ë¦¬ë“œ ê±°ë¦¬": EuclideanDistanceAlgorithm(centroids, norm_cols),
        "í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜": PearsonCorrelationAlgorithm(centroids, norm_cols),
        "ì¸ê¸°ë„ ê¸°ë°˜": PopularityAlgorithm(centroids, norm_cols, recommend_result),
        "í˜‘ì—… í•„í„°ë§": CollaborativeAlgorithm(centroids, norm_cols, recommend_result),
        "AHP-TOPSIS": AHPTopsisAlgorithm(centroids, norm_cols, recommend_result),
    }
    
    print(f"\nğŸš€ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘: {len(queries)}ê°œ ì¿¼ë¦¬ Ã— {iterations}íšŒ ë°˜ë³µ\n")
    
    results = []
    
    for algo_name, algo in algorithms.items():
        print(f"â±ï¸  {algo_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        total_time = 0
        success_count = 0
        error_count = 0
        
        for query in queries:
            for i in range(iterations):
                try:
                    # ì£¼ì†Œ ê²€ìƒ‰
                    filtered_df = gas_df[gas_df["ì£¼ì†Œ"].astype(str).str.contains(query, na=False)]
                    
                    if filtered_df.empty:
                        filtered_df = gas_df[gas_df["í–‰ì •êµ¬ì—­"].astype(str).str.contains(query, na=False)]
                    
                    if not filtered_df.empty:
                        start_time = time.time()
                        recommendations = algo.recommend(filtered_df, 10)
                        execution_time = time.time() - start_time
                        
                        total_time += execution_time
                        success_count += 1
                    
                except Exception as e:
                    error_count += 1
                    print(f"  âŒ ì˜¤ë¥˜: {query} - {str(e)}")
        
        avg_time = (total_time / success_count) if success_count > 0 else 0
        
        results.append({
            "ì•Œê³ ë¦¬ì¦˜": algo_name,
            "ì„±ê³µ": success_count,
            "ì‹¤íŒ¨": error_count,
            "í‰ê·  ì‹œê°„(ms)": round(avg_time * 1000, 2),
            "ì´ ì‹œê°„(s)": round(total_time, 2)
        })
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*70)
    print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼")
    print("="*70 + "\n")
    
    df_results = pd.DataFrame(results)
    df_results = df_results.sort_values("í‰ê·  ì‹œê°„(ms)")
    
    print(df_results.to_string(index=False))
    
    print("\n" + "="*70)
    print(f"ğŸ† ê°€ì¥ ë¹ ë¥¸ ì•Œê³ ë¦¬ì¦˜: {df_results.iloc[0]['ì•Œê³ ë¦¬ì¦˜']}")
    print(f"âš¡ í‰ê·  ì‹¤í–‰ ì‹œê°„: {df_results.iloc[0]['í‰ê·  ì‹œê°„(ms)']} ms")
    print("="*70 + "\n")
    
    return df_results


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    parser.add_argument(
        "--queries",
        nargs="+",
        default=["ì„œìš¸ ê°•ë‚¨êµ¬", "ë¶€ì‚° í•´ìš´ëŒ€êµ¬", "ì „ì£¼ì‹œ"],
        help="í…ŒìŠ¤íŠ¸í•  ì£¼ì†Œ ëª©ë¡"
    )
    parser.add_argument(
        "--iterations",
        type=int,
        default=5,
        help="ê° ì¿¼ë¦¬ë‹¹ ë°˜ë³µ íšŸìˆ˜"
    )
    
    args = parser.parse_args()
    run_benchmark(args.queries, args.iterations)


if __name__ == "__main__":
    main()
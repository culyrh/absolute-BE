"""
ì£¼ìœ ì†Œ ì •ë³´ ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸
"""

from collections import Counter
from html import escape
from typing import Optional, List, Dict, Any
from datetime import datetime


import json
import traceback
import pandas as pd
import folium
import math
import requests
from fastapi import APIRouter, Depends, Query, HTTPException, Path
from fastapi.responses import JSONResponse, HTMLResponse, FileResponse
from shapely.geometry import Point

from app.api.dependencies import get_geo_service, get_report_service
from app.schemas.gas_station import GasStationList, GasStationResponse
from app.services.geo_service import GeoService
from app.services.parcel_service import get_parcel_service
from app.services.report_service import LLMReportService
from app.services.terrain_service import TerrainMapService
from app.core.config import DATA_DIR


from dotenv import load_dotenv
load_dotenv()

from app.core.config import get_settings
settings = get_settings()

router = APIRouter(
    prefix="/api/stations",
    tags=["gas_stations"],
    responses={404: {"description": "Not found"}},
)


METERS_PER_DEGREE = 111_000


def _classify_parcel_area(area_m2: float) -> str:
    if area_m2 < 300:
        return "ì†Œí˜•"
    if area_m2 < 1000:
        return "ì¤‘í˜•"
    if area_m2 < 3000:
        return "ëŒ€í˜•"
    return "ì´ˆëŒ€í˜•"


def _extract_land_use(row: Dict[str, Any]) -> Optional[str]:
    candidate_keys = [
        "JIMOK",
        "JIGU",
        "USEDSGN",
        "USE",
        "LAND_USE",
        "ZONING",
        "ì§€ëª©",
        "ìš©ë„ì§€ì—­",
    ]
    for key in candidate_keys:
        value = row.get(key)
        if value:
            return str(value)
    return None


def _format_recommendations_from_api_payload(payload: Dict[str, Any]) -> List[Dict[str, Any]]:
    """/{id}/recommend API ì‘ë‹µì„ ë³´ê³ ì„œì—ì„œ ì‚¬ìš©í•˜ëŠ” í¬ë§·ìœ¼ë¡œ ë³€í™˜í•œë‹¤."""

    if not isinstance(payload, dict):
        return []

    formatted: List[Dict[str, Any]] = []
    for rank in range(1, 6):
        key = f"recommend{rank}"
        usage_value = payload.get(key)
        if usage_value is None:
            continue

        usage_text = str(usage_value).strip()
        if not usage_text or usage_text.lower() == "nan":
            continue

        formatted.append(
            {
                "type": usage_text,
                "rank": rank,
                "source": "station_recommend_api",
                "description": f"ì¶”ì²œ API ê²°ê³¼ ìˆœìœ„ {rank}ìœ„",
            }
        )

    return formatted


def _summarise_nearby_parcels(gdf, lat: float, lng: float) -> Optional[Dict[str, Any]]:
    if gdf is None or getattr(gdf, "empty", True):
        return None

    bucket_counter: Counter[str] = Counter()
    total_area = 0.0
    land_use_counter: Counter[str] = Counter()
    closest_info: Optional[Dict[str, Any]] = None
    station_point = Point(lng, lat)

    for _, row in gdf.iterrows():
        geometry = row.get("geometry")
        if geometry is None or geometry.is_empty:
            continue

        try:
            area_m2 = abs(float(geometry.area)) * (METERS_PER_DEGREE ** 2)
        except Exception:
            area_m2 = 0.0

        if area_m2 > 0:
            bucket_counter[_classify_parcel_area(area_m2)] += 1
            total_area += area_m2

        land_use = _extract_land_use(row)
        if land_use:
            land_use_counter[land_use] += 1

        try:
            distance_m = geometry.centroid.distance(station_point) * METERS_PER_DEGREE
        except Exception:
            distance_m = None

        if distance_m is not None:
            if not closest_info or distance_m < closest_info.get("distance_m", float("inf")):
                closest_info = {
                    "distance_m": float(distance_m),
                    "label": row.get("JIBUN") or row.get("PNU") or row.get("LOTNO") or row.get("BUNJI"),
                }

    total_count = sum(bucket_counter.values())
    if total_count == 0:
        return None

    average_area = total_area / total_count if total_count else 0
    top_land_uses = [
        {"use": use, "count": count}
        for use, count in land_use_counter.most_common(3)
    ]

    return {
        "total_count": total_count,
        "total_area": total_area,
        "average_area": average_area,
        "bucket_counts": dict(bucket_counter),
        "top_land_uses": top_land_uses,
        "closest": closest_info,
    }


def kakao_local_search(query: str):
    """
    Kakao Local API â€” ë°˜ê²½ ê²€ìƒ‰ ì—†ì´ query ê¸°ë°˜ ê²€ìƒ‰
    """
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {
        "Authorization": f"KakaoAK {settings.KAKAO_REST_API_KEY}"
    }

    params = {
        "query": query,
        "size": 15
    }

    r = requests.get(url, headers=headers, params=params)

    if r.status_code != 200:
        return []

    docs = r.json().get("documents", [])
    results = []

    for d in docs:
        try:
            results.append({
                "name": d.get("place_name"),
                "lat": float(d.get("y")),
                "lng": float(d.get("x")),
                "address": d.get("address_name"),
                "road_address": d.get("road_address_name")
            })
        except:
            continue

    return results


# ============================================================
# í•„ì§€(ê°œë³„ê³µì‹œì§€ê°€ + í† ì§€ì´ìš©ê³„íš) ì •ë³´ CSV ë¡œë”
# ============================================================

LAND_PRICE_PATH = DATA_DIR / "station_with_landprice.csv"
LAND_USE_PATH = DATA_DIR / "station_with_landuse.csv"

# CSVëŠ” lazy loadingìœ¼ë¡œë§Œ ì²˜ë¦¬ â†’ import ì‹œì ì— ì ˆëŒ€ ì½ì§€ ì•ŠìŒ
def load_land_price_df():
    try:
        return pd.read_csv(LAND_PRICE_PATH, dtype=str)
    except Exception as e:
        print("âš  land price csv ë¡œë”© ì˜¤ë¥˜:", e)
        return None

def load_land_use_df():
    try:
        return pd.read_csv(LAND_USE_PATH, dtype=str)
    except Exception as e:
        print("âš  land use csv ë¡œë”© ì˜¤ë¥˜:", e)
        return None

def _classify_landuse(code: str, name: str) -> str:
    """
    ìš©ë„ì§€ì—­ì§€êµ¬ì½”ë“œ â†’ ëŒ€ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    - 'zoning'       : ìš©ë„ì§€ì—­/ì§€êµ¬ (ì£¼ê±°Â·ìƒì—…Â·ê³µì—…Â·ë…¹ì§€, ê´€ë¦¬ì§€ì—­ ë“±)
    - 'infra'        : ë„ë¡œÂ·ì² ë„Â·ì£¼ì°¨ì¥Â·í•˜ì²œ ë“± ê¸°ë°˜ì‹œì„¤
    - 'environment'  : í™˜ê²½Â·ë³´ì „Â·ê·œì œ ê¶Œì—­
    - 'development'  : ê°œë°œí–‰ìœ„Â·ì§€êµ¬ë‹¨ìœ„Â·ë„ì‹œê´€ë¦¬ê³„íš ë“±
    - 'other'        : ìœ„ì— ì•ˆ ê±¸ë¦¬ëŠ” ë‚˜ë¨¸ì§€
    """
    code = (code or "").upper()

    # ìš©ë„ì§€ì—­Â·ìš©ë„ì§€êµ¬
    if code.startswith(("UQA", "UQB", "UQC", "UQD")):
        return "zoning"

    # ë„ë¡œ, ì² ë„, ì£¼ì°¨ì¥, í•˜ì²œ ë“± ê¸°ë°˜ì‹œì„¤
    if code.startswith(("UIA", "UIK", "UQS", "UJB", "UQW")) or code in {
        "UQS200", "UQS210", "UQS510"
    }:
        return "infra"

    # í™˜ê²½Â·ë³´ì „Â·ê·œì œ ê¶Œì—­
    if code.startswith(("UMZ", "UMN", "UMX", "UG", "UOC")) or code in {
        "UBA100", "UBA200", "UBA300", "UDV100"
    }:
        return "environment"

    # ê°œë°œ ê´€ë ¨(ì§€êµ¬ë‹¨ìœ„, ê°œë°œì œí•œêµ¬ì—­, ì„±ì¥/ê°œë°œì§€êµ¬ ë“±)
    if code.startswith(("UQQ", "UQN", "UQM", "UHA", "UHG", "UHJ", "UM2", "UFM", "UHB", "UHD")):
        return "development"

    return "other"



# ============================================================
# API ì—”ë“œí¬ì¸íŠ¸
# ============================================================

@router.get("/region/{code:path}")
async def get_geojson_by_region(
    code: str = Path(..., description="ì§€ì—­ ì½”ë“œ (ì˜ˆ: ì„œìš¸íŠ¹ë³„ì‹œ, ì „ì£¼ì‹œ ë“±)"),
    limit: int = Query(5000, ge=1, le=5000, description="ë°˜í™˜í•  ê²°ê³¼ ìˆ˜"),
    service: GeoService = Depends(get_geo_service),
):
    """
    ì§€ì—­ë³„ ì£¼ìœ ì†Œ ëª©ë¡ GeoJSON API
    """
    try:
        # ì§€ì—­ ë°ì´í„° ì¡°íšŒ
        result = service.search_by_address(code, limit)
        if not result:
            return JSONResponse(content={"type": "FeatureCollection", "features": []})

        # GeoJSON í˜•íƒœë¡œ ë³€í™˜
        features = []
        for item in result:
            try:
                lon = float(item.get("ê²½ë„"))
                lat = float(item.get("ìœ„ë„"))
            except (ValueError, TypeError):
                continue  # ì¢Œí‘œ ì—†ëŠ” í•­ëª©ì€ ì œì™¸

            feature = {
                "type": "Feature",
                "geometry": {
                    "type": "Point",
                    "coordinates": [lon, lat]
                },
                "properties": {
                    k: v for k, v in item.items()
                    if k not in ["ê²½ë„", "ìœ„ë„"]
                }
            }
            features.append(feature)

        # GeoJSON ë°˜í™˜
        geojson = {
            "type": "FeatureCollection",
            "features": features
        }

        headers = {"Cache-Control": "public, max-age=3600"}
        return JSONResponse(content=geojson, headers=headers)

    except Exception as e:
        print(f"ì§€ì—­ë³„ GeoJSON ë³€í™˜ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"GeoJSON ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


@router.get("/map", response_model=GasStationList)
async def get_stations_in_map(
    lat1: float = Query(..., description="ìœ„ë„ ìµœì†Œê°’"),
    lng1: float = Query(..., description="ê²½ë„ ìµœì†Œê°’"),
    lat2: float = Query(..., description="ìœ„ë„ ìµœëŒ€ê°’"),
    lng2: float = Query(..., description="ê²½ë„ ìµœëŒ€ê°’"),
    limit: int = Query(10000, ge=1, le=10000, description="ë°˜í™˜í•  ê²°ê³¼ ìˆ˜"),
    service: GeoService = Depends(get_geo_service),
):
    """
    ì§€ë„ ë²”ìœ„ ë‚´ ì£¼ìœ ì†Œ API
    
    - **lat1**: ìœ„ë„ ìµœì†Œê°’ (í•„ìˆ˜)
    - **lng1**: ê²½ë„ ìµœì†Œê°’ (í•„ìˆ˜)
    - **lat2**: ìœ„ë„ ìµœëŒ€ê°’ (í•„ìˆ˜)
    - **lng2**: ê²½ë„ ìµœëŒ€ê°’ (í•„ìˆ˜)
    - **limit**: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 10000, ìµœëŒ€: 10000)
    """
    try:
        # ííœ´ì—… ì£¼ìœ ì†Œ ë°ì´í„°ì—ì„œ ì¢Œí‘œë¡œ ê²€ìƒ‰

        # preprocess_gas_station_dataì˜ processed_df ë°˜í™˜ 
        # -> (í–‰ì •êµ¬ì—­, ê¶Œì—­) ì»¬ëŸ¼ ì¶”ê°€ / idxê°€ ë¶€ì—¬ëœ station ë°ì´í„°
        gas_df = service.data.get("gas_station", None)
        
        # ì¢Œí‘œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ê²°ê³¼ ë°˜í™˜
        if gas_df is None or "ìœ„ë„" not in gas_df.columns or "ê²½ë„" not in gas_df.columns:
            return JSONResponse(content={"count": 0, "items": []})
        
        # ì¢Œí‘œ ë²”ìœ„ ë‚´ ë°ì´í„° í•„í„°ë§
        filtered_df = gas_df[
            (gas_df["ìœ„ë„"] >= lat1) & 
            (gas_df["ìœ„ë„"] <= lat2) & 
            (gas_df["ê²½ë„"] >= lng1) & 
            (gas_df["ê²½ë„"] <= lng2)
        ]
        
        filtered_df = filtered_df[
            filtered_df["ìœ„ë„"].apply(lambda x: isinstance(x, (int, float))) &
            filtered_df["ê²½ë„"].apply(lambda x: isinstance(x, (int, float)))
        ]

        # NaN â†’ None ë³€í™˜
        clean_df = filtered_df.where(filtered_df.notnull(), None)

        # ê²°ê³¼ í˜•ì‹í™”
        result = clean_df.head(limit).to_dict("records")

        # JSON ì§ë ¬í™” ì˜¤ë¥˜ í•´ê²° / ëª¨ë“  ì†ì„±ì˜ ê²°ì¸¡ì¹˜ ì œê±°
        def sanitize_value(v):
            if v is None:
                return None
            # NaN ë˜ëŠ” Infinite â†’ None
            if isinstance(v, float) and (math.isnan(v) or math.isinf(v)):
                return None
            return v

        # ëª¨ë“  ë ˆì½”ë“œì— ëŒ€í•´ NaN/inf ì •ë¦¬
        result = [
            {k: sanitize_value(v) for k, v in item.items()}
            for item in result
        ]            
        
        # ìºì‹± í—¤ë” ì„¤ì • (5ë¶„)
        headers = {"Cache-Control": "public, max-age=300"}
        
        return JSONResponse(
            content={"count": len(result), "items": result},
            headers=headers
        )
    except Exception as e:
        print(f"ì§€ë„ ë²”ìœ„ ë‚´ ì£¼ìœ ì†Œ API ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì§€ë„ ë²”ìœ„ ë‚´ ì£¼ìœ ì†Œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@router.get("/search", response_model=GasStationList)
async def search_stations(
    query: str = Query(..., description="ì£¼ìœ ì†Œ ì´ë¦„ ê²€ìƒ‰ì–´"),
    limit: int = Query(100, ge=1, le=1000, description="ë°˜í™˜í•  ê²°ê³¼ ìˆ˜"),
    service: GeoService = Depends(get_geo_service),
):
    """
    ì£¼ìœ ì†Œëª… ê¸°ë°˜ ê²€ìƒ‰ API

    - **query**: ì£¼ìœ ì†Œëª… ê²€ìƒ‰ì–´ (ì˜ˆ: 'í˜„ëŒ€', 'SK', 'ëª©í™”')
    - **limit**: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 100, ìµœëŒ€: 1000)
    """
    try:
        # ì£¼ìœ ì†Œ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
        result = service.search_by_name(query, limit)
        
        # GeoJSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        features = []
        for item in result:
            try:
                lon = float(item.get("ê²½ë„"))
                lat = float(item.get("ìœ„ë„"))
            except (ValueError, TypeError):
                continue

            feature = {
                "type": "Feature",
                "geometry": {
                    "type": "Point",
                    "coordinates": [lon, lat]
                },
                "properties": {
                    k: v for k, v in item.items() if k not in ["ê²½ë„", "ìœ„ë„"]
                }
            }
            features.append(feature)

        geojson = {
            "type": "FeatureCollection",
            "features": features
        }

        return JSONResponse(content=geojson)

    except Exception as e:
        print(f"ì£¼ìœ ì†Œëª… ê¸°ë°˜ ê²€ìƒ‰ API ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì£¼ìœ ì†Œëª… ê¸°ë°˜ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")



# ============================================================
# ì£¼ìœ ì†Œ ê°œë³„ ì •ë³´ API
# ============================================================

BJD_PATH = DATA_DIR / "ë²•ì •ë™_ì½”ë“œ_ì „ì²´ìë£Œ.csv"
BJD_DF = None

def load_bjd_df():
    global BJD_DF
    if BJD_DF is not None:
        return BJD_DF

    df = pd.read_csv(BJD_PATH, dtype=str)

    def norm(code):
        s = str(code).strip()
        if s.endswith(".0"):
            s = s[:-2]
        s = "".join(c for c in s if c.isdigit())
        if len(s) == 8:
            s += "00"
        if len(s) < 10:
            s = s.ljust(10, "0")
        return s[:10]

    df["ë²•ì •ë™ì½”ë“œ"] = df["ë²•ì •ë™ì½”ë“œ"].apply(norm)
    BJD_DF = df
    return df

def get_bjd_name_from_adm(adm_cd2):
    """adm_cd2 â†’ ì •ê·œí™” â†’ ë²•ì •ë™ëª… ë°˜í™˜"""
    if adm_cd2 is None:
        return None

    df = load_bjd_df()

    s = str(adm_cd2).strip()
    if s.endswith(".0"):
        s = s[:-2]
    s = "".join(c for c in s if c.isdigit())
    if len(s) == 8:
        s += "00"
    if len(s) < 10:
        s = s.ljust(10, "0")
    s = s[:10]

    row = df[df["ë²•ì •ë™ì½”ë“œ"] == s]
    if len(row) == 0:
        return None

    return row["ë²•ì •ë™ëª…"].iloc[0]

@router.get("/{id}/vehicle")
async def get_vehicle_services(
    id: str = Path(..., description="ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  ID"),
    service: GeoService = Depends(get_geo_service)
):
    df = service.data.get("gas_station")
    if df is None or df.empty:
        raise HTTPException(status_code=500, detail="station.csv ì—†ìŒ")

    # 1) ID â†’ ì¢Œí‘œ ë³µêµ¬
    try:
        lat_part, lng_part = id.split("_")
        lat = float(lat_part) / 1_000_000
        lng = float(lng_part) / 1_000_000
    except:
        raise HTTPException(status_code=400, detail="ID í˜•ì‹ ì˜¤ë¥˜")

    # 2) ê°€ì¥ ê°€ê¹Œìš´ station
    df["distance"] = (df["ìœ„ë„"] - lat)**2 + (df["ê²½ë„"] - lng)**2
    station = df.loc[df["distance"].idxmin()].to_dict()

    # 3) adm_cd2 ê¸°ë°˜ ë²•ì •ë™ëª… ì°¾ê¸° **(í•µì‹¬ íŒ¨ì¹˜)**
    adm_raw = (
        station.get("ë²•ì •ë™ì½”ë“œ") or
        station.get("adm_cd2") or
        station.get("ë²•ì •ë™ ì½”ë“œ")
    )
    region = get_bjd_name_from_adm(adm_raw)

    if not region:
        return {
            "id": id,
            "region": None,
            "ì •ë¹„ì†Œ": [],
            "ì„¸ì°¨ì¥": [],
            "íƒ€ì´ì–´": [],
            "ì¹´ì„¼í„°": [],
            "total_count": 0
        }

    # 4) Kakao ê²€ìƒ‰
    repair = kakao_local_search(f"ì •ë¹„ì†Œ {region}")
    wash   = kakao_local_search(f"ì„¸ì°¨ì¥ {region}")
    tire   = kakao_local_search(f"íƒ€ì´ì–´ {region}")
    center = kakao_local_search(f"ì¹´ì„¼í„° {region}")

    total = len(repair) + len(wash) + len(tire) + len(center)

    return {
        "id": id,
        "region": region,
        "ì •ë¹„ì†Œ": repair,
        "ì„¸ì°¨ì¥": wash,
        "íƒ€ì´ì–´": tire,
        "ì¹´ì„¼í„°": center,
        "total_count": total
    }


# ============================================================

@router.get("/{id}/ev")
async def get_ev_chargers(
    id: str = Path(..., description="ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  ID"),
    service: GeoService = Depends(get_geo_service)
):
    df = service.data.get("gas_station")
    if df is None or df.empty:
        raise HTTPException(status_code=500, detail="station.csv ì—†ìŒ")

    # ID â†’ ì¢Œí‘œ ë³µêµ¬
    try:
        lat_part, lng_part = id.split("_")
        lat = float(lat_part) / 1_000_000
        lng = float(lng_part) / 1_000_000
    except:
        raise HTTPException(status_code=400, detail="ID í˜•ì‹ ì˜¤ë¥˜")

    # ê°€ì¥ ê°€ê¹Œìš´ station
    df["distance"] = (df["ìœ„ë„"] - lat)**2 + (df["ê²½ë„"] - lng)**2
    station = df.loc[df["distance"].idxmin()].to_dict()

    # adm_cd2 ê¸°ë°˜ ë²•ì •ë™ëª… ì°¾ê¸° **(í•µì‹¬ íŒ¨ì¹˜)**
    adm_raw = (
        station.get("ë²•ì •ë™ì½”ë“œ") or
        station.get("adm_cd2") or
        station.get("ë²•ì •ë™ ì½”ë“œ")
    )
    region = get_bjd_name_from_adm(adm_raw)

    if not region:
        return {"id": id, "region": None, "items": [], "count": 0}

    # Kakao ê²€ìƒ‰
    ev = kakao_local_search(f"ì „ê¸°ì°¨ì¶©ì „ì†Œ {region}") or []

    return {
        "id": id,
        "region": region,
        "items": ev,
        "count": len(ev)
    }


@router.get("/{id}/recommend")
async def get_station_recommend(
    id: str = Path(..., description="ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  ID (ì˜ˆ: 35689819_128445642)"),
    service: GeoService = Depends(get_geo_service),
):
    """
    ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  IDë¡œ ì¶”ì²œ í™œìš©ë°©ì•ˆ ì¡°íšŒ
    """
    try:
        df = service.data.get("gas_station")

        # id = "37384645_126941288" â†’ lat,lng ë³µì›
        try:
            lat_part, lng_part = id.split("_")
            lat = float(lat_part) / 1000000
            lng = float(lng_part) / 1000000
        except:
            raise HTTPException(status_code=400, detail="ID í˜•ì‹ ì˜¤ë¥˜")

        # ê°€ê¹Œìš´ station ì°¾ê¸°
        df["distance"] = ((df["ìœ„ë„"] - lat)**2 + (df["ê²½ë„"] - lng)**2)
        station = df.loc[df["distance"].idxmin()].to_dict()
        station.pop("distance", None)

        return JSONResponse(
            content={
                "id": id,
                "name": station.get("ìƒí˜¸"),
                "address": station.get("ì£¼ì†Œ"),
                "recommend1": station.get("recommend1"),
                "recommend2": station.get("recommend2"),
                "recommend3": station.get("recommend3"),
            }
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¶”ì²œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")


@router.get("/{id}/stats")
async def get_station_stats(
    id: str = Path(..., description="ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  ID (ì˜ˆ: 35689819_128445642)"),
    service: GeoService = Depends(get_geo_service),
):
    """
    íŠ¹ì • ì£¼ìœ ì†Œ(id)ì˜ ì •ëŸ‰ ì§€í‘œ + ê¶Œì—­(train ê¸°ë°˜) ë¹„êµ API
    - parcel_300m, parcel_500m, êµí†µëŸ‰, ê´€ê´‘ì§€ìˆ˜, ì¸êµ¬, ìƒê¶Œë°€ì§‘ë„
    - train.csv ê¸°ë°˜ ì‹œë„(region_code)ë³„ í‰ê· ê³¼ ë¹„êµ
    """

    try:
        # -------------------------------------------
        # 1) station.csv ë¡œë”©
        # -------------------------------------------
        df_station = service.data.get("gas_station")
        if df_station is None or df_station.empty:
            raise HTTPException(status_code=500, detail="station.csv ì—†ìŒ")

        df_station = df_station.loc[:, ~df_station.columns.duplicated()]

        # -------------------------------------------
        # 2) ì¢Œí‘œ ê¸°ë°˜ ID íŒŒì‹±
        # -------------------------------------------
        try:
            lat_part, lng_part = id.split("_")
            lat = float(lat_part) / 1_000_000
            lng = float(lng_part) / 1_000_000
        except:
            raise HTTPException(status_code=400, detail="ID í˜•ì‹ ì˜¤ë¥˜")

        # -------------------------------------------
        # 3) ê°€ì¥ ê°€ê¹Œìš´ station ì°¾ê¸°
        # -------------------------------------------
        df_station["distance"] = (
            (df_station["ìœ„ë„"] - lat)**2 +
            (df_station["ê²½ë„"] - lng)**2
        )
        station = df_station.loc[df_station["distance"].idxmin()].to_dict()
        station.pop("distance", None)

        # -------------------------------------------
        # 4-A) stationì—ì„œ adm_cd2 ì›ë³¸ ì¶”ì¶œ
        # -------------------------------------------
        adm_raw = None

        for key in ["adm_cd2", "ë²•ì •ë™ì½”ë“œ", "ë²•ì •ë™ ì½”ë“œ"]:
            if station.get(key) is not None:
                adm_raw = station.get(key)
                break

        # ìˆ˜ì •: adm_cd2 ì—†ìœ¼ë©´ ì—ëŸ¬ ë‚´ì§€ ë§ê³  ë¹ˆ ê°’ ë°˜í™˜
        if adm_raw is None or str(adm_raw).strip() == "" or str(adm_raw).lower() == "nan":
            return JSONResponse(
                content={
                    "id": id,
                    "region_code": None,
                    "metrics": {},
                    "train_mean": {},
                    "relative": {},
                    "percentile": {}
                }
            )

        # -------------------------------------------
        # 4-B) adm_cd2 ì •ê·œí™” í•¨ìˆ˜
        # -------------------------------------------
        def normalize_adm_cd2(value):
            if value is None:
                return None

            s = str(value).strip()

            # float í˜•íƒœ ".0" ì œê±°
            if s.endswith(".0"):
                s = s[:-2]

            # ìˆ«ìë§Œ ë‚¨ê¸°ê¸°
            s = "".join(ch for ch in s if ch.isdigit())

            # 8ìë¦¬ ë²•ì •ë™ â†’ 10ìë¦¬ ë³€í™˜
            if len(s) == 8:
                s += "00"

            # ê¸¸ì´ ë¶€ì¡±í•˜ë©´ 0ìœ¼ë¡œ íŒ¨ë”©
            if len(s) < 10:
                s = s.ljust(10, "0")

            # 10ìë¦¬ë¡œ ìë¥´ê¸°
            return s[:10]

        # -------------------------------------------
        # 5) station region_code ìƒì„±
        # -------------------------------------------
        adm_cd = normalize_adm_cd2(adm_raw)
        if not adm_cd:
            raise HTTPException(status_code=500, detail="station adm_cd2 ì˜¤ë¥˜")

        region_code = adm_cd[:2]

        # -------------------------------------------
        # 6) train.csv ë¡œë“œ
        # -------------------------------------------
        from app.services.geoai_config import GeoAIConfig
        cfg = GeoAIConfig()

        train_path = cfg.data_dir / "train.csv"
        if not train_path.exists():
            raise HTTPException(status_code=500, detail="train.csv ì—†ìŒ")

        df_train = pd.read_csv(train_path)

        df_train["adm_cd2_norm"] = df_train["adm_cd2"].apply(normalize_adm_cd2)
        df_train["region_code"] = df_train["adm_cd2_norm"].str[:2]

        region_train = df_train[df_train["region_code"] == region_code]
        if region_train.empty:
            raise HTTPException(
                status_code=404,
                detail=f"train.csv ì— region_code={region_code} ë°ì´í„° ì—†ìŒ"
            )

        # -------------------------------------------
        # 7) station â†” train ì§€í‘œ ë§¤ì¹­
        # -------------------------------------------
        FEATURE_COLS = {
            "traffic": ("êµí†µëŸ‰", "êµí†µëŸ‰(AADT)"),
            "tourism": ("ê´€ê´‘ì§€ìˆ˜", "ìˆ™ë°•ì—…ì†Œ(ê´€ê´‘ì§€ìˆ˜)"),
            "population": ("ì¸êµ¬", "ì¸êµ¬[ëª…]"),
            "commercial_density": ("ìƒê¶Œë°€ì§‘ë„", "ìƒê¶Œë°€ì§‘ë„(ë¹„ìœ¨)"),
            "parcel_300m": ("parcel_300m", "parcel_300m"),
            "parcel_500m": ("parcel_500m", "parcel_500m"),
        }

        # -------------------------------------------
        # 8) station ì§€í‘œ ì½ê¸°
        # -------------------------------------------
        metrics = {
            name: station.get(st_col)
            for name, (st_col, tr_col) in FEATURE_COLS.items()
        }

        # -------------------------------------------
        # 9) train í‰ê·  ê³„ì‚°
        # -------------------------------------------
        train_mean = {
            name: float(region_train[tr_col].mean())
            for name, (st_col, tr_col) in FEATURE_COLS.items()
            if tr_col in region_train.columns   # ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        }

        # -------------------------------------------
        # 10) ë³€í™”ìœ¨ ê³„ì‚°
        # -------------------------------------------
        def percent_change(a, b):
            if a is None or b is None or b == 0:
                return None
            return (float(a) - float(b)) / float(b) * 100

        relative = {
            name: percent_change(metrics[name], train_mean[name])
            for name in FEATURE_COLS.keys()
            if name in train_mean   # train_meanì— ì¡´ì¬í•˜ëŠ” ì§€í‘œë§Œ
        }

        # -------------------------------------------
        # 11) ë°±ë¶„ìœ„ ê³„ì‚°
        # -------------------------------------------
        def percentile(series, value):
            if value is None:
                return None
            # ë¬¸ìì—´ â†’ ìˆ«ì ë³€í™˜ (ì˜¤ë¥˜ ë°©ì§€)
            try:
                value = float(value)
            except:
                return None

            arr = pd.to_numeric(series, errors="coerce").dropna().values
            if len(arr) == 0:
                return None
            
            return float((arr < value).mean() * 100)

        percentiles = {
            name: percentile(region_train[tr_col], metrics[name])
            for name, (st_col, tr_col) in FEATURE_COLS.items()
            if name in train_mean   # train_meanì— ì¡´ì¬í•˜ëŠ” ì§€í‘œë§Œ
        }

        # -------------------------------------------
        # 12) ìµœì¢… ì‘ë‹µ
        # -------------------------------------------
        return JSONResponse(
            content={
                "id": id,
                "region_code": region_code,
                "metrics": metrics,
                "train_mean": train_mean,
                "relative": relative,
                "percentile": percentiles,
            }
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{id}/report", response_class=HTMLResponse)
async def generate_station_report(
    id: str = Path(..., description="ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  ID (ì˜ˆ: 35689819_128445642)"),
    service: GeoService = Depends(get_geo_service),
    report_service: LLMReportService = Depends(get_report_service)
):
    """
    ì£¼ìœ ì†Œ ì…ì§€ ë¶„ì„ ë³´ê³ ì„œ (ì§€ì ë„ í¬í•¨)
    - ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  ID ì‚¬ìš©
    """
    try:
        df = service.data.get("gas_station")

        if df is None or df.empty:
            raise HTTPException(status_code=500, detail="ì£¼ìœ ì†Œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        # ----------------------------------
        # 1) ì¢Œí‘œ ê¸°ë°˜ ID íŒŒì‹±
        # ----------------------------------
        try:
            lat_part, lng_part = id.split("_")
            lat = float(lat_part) / 1_000_000
            lng = float(lng_part) / 1_000_000
        except:
            raise HTTPException(status_code=400, detail="ID í˜•ì‹ ì˜¤ë¥˜ (ì˜ˆ: 35689819_128445642)")

        # ----------------------------------
        # 2) ê°€ì¥ ê°€ê¹Œìš´ station ì°¾ê¸°
        # ----------------------------------
        df = df.loc[:, ~df.columns.duplicated()]  # ì¤‘ë³µëœ ìœ„ë„/ê²½ë„ ì •ë¦¬

        df["distance"] = ((df["ìœ„ë„"] - lat)**2 + (df["ê²½ë„"] - lng)**2)
        nearest_idx = df["distance"].idxmin()
        station = df.loc[nearest_idx].to_dict()
        station.pop("distance", None)

        # station ê³ ìœ  idëŠ” ì¢Œí‘œ idë¡œ ì¬ì •ì˜
        station_id = id  

        # ----------------------------------
        # ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ
        # ----------------------------------

        name = station.get('ìƒí˜¸', 'ì£¼ìœ ì†Œ')
        address = station.get('ì£¼ì†Œ', '')

        # 2. ì¶”ì²œ ê²°ê³¼ (/{id}/recommend API í™œìš©)
        combined_recommendations: List[Dict[str, Any]] = []
        try:
            recommend_response = await get_station_recommend(id=id, service=service)
            raw_body = getattr(recommend_response, "body", b"")
            payload = json.loads(raw_body.decode("utf-8")) if raw_body else {}
            combined_recommendations = _format_recommendations_from_api_payload(payload)
        except Exception as rec_error:
            print(f"ì¶”ì²œ API í˜¸ì¶œ ì˜¤ë¥˜: {rec_error}")

        parcel_summary = None
        land_payload: Dict[str, Any] = {}

        # 3. ì§€ë„ ìƒì„±
        m = folium.Map(location=[lat, lng], zoom_start=17, tiles='OpenStreetMap')

        try:
            parcel_service = get_parcel_service()
            nearby_parcels = parcel_service.get_nearby_parcels(lat, lng, radius=0.003)
            parcel_summary = _summarise_nearby_parcels(nearby_parcels, lat, lng)
        except Exception as parcel_error:
            print(f"ì§€ì ë„ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {parcel_error}")
            nearby_parcels = None

        try:
            land_response = await get_station_land(id=id, service=service)
            raw_land_body = getattr(land_response, "body", b"")
            land_payload = json.loads(raw_land_body.decode("utf-8")) if raw_land_body else {}
        except Exception as land_error:
            print(f"í•„ì§€ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {land_error}")

        terrain_png_path = f"/api/stations/{station_id}/terrain"

        terrain_img_html = f"""
            <img src="{terrain_png_path}"
                style="width:100%; border-radius:12px; border:1px solid #ccc;">
        """

        map_images = report_service.prepare_map_images(lat, lng)

        stats_payload: Dict[str, Any] = {}
        try:
            stats_response = await get_station_stats(id=id, service=service)
            raw_stats_body = getattr(stats_response, "body", b"")
            stats_payload = json.loads(raw_stats_body.decode("utf-8")) if raw_stats_body else {}
        except Exception as stats_error:
            print(f"ë¶„ì„ ì§€í‘œ ì¡°íšŒ ì˜¤ë¥˜: {stats_error}")

        llm_report = await report_service.generate_report(
            station,
            combined_recommendations,
            parcel_summary=parcel_summary,
            station_id=station_id,
            map_images=map_images,
            stats_payload=stats_payload,
        )

        # ------------------------------
        # 4. ì¹´ì¹´ì˜¤ ì§€ë„ (ì •ì ì²˜ëŸ¼ ê³ ì •)
        # ------------------------------
        js_key = "ef6066b015b62cbc9689dbf67268deb1"

        map_html = f"""
        <div id="report-map"
            style="width:100%;height:100%;border-radius:12px;overflow:hidden;"></div>

        <script>
            (function () {{
            var script = document.createElement('script');
            script.src = "https://dapi.kakao.com/v2/maps/sdk.js?autoload=false&appkey={js_key}&libraries=services";
            script.onload = function () {{
                kakao.maps.load(function () {{
                var container = document.getElementById('report-map');
                if (!container) return;

                // í™”ë©´ ê¸°ë³¸ ì¤‘ì‹¬
                var center = new kakao.maps.LatLng({lat}, {lng});
                // ğŸ”½ ì¸ì‡„í•  ë•ŒëŠ” ì§€ë„ë¥¼ ì¡°ê¸ˆ ìœ„ë¡œ ì˜¬ë ¤ì„œ(ìœ„ë„ +) ë§ˆì»¤ê°€ ì•„ë˜ìª½ì— ë³´ì´ê²Œ
                var printCenter = new kakao.maps.LatLng({lat} + 0.0016, {lng});

                var map = new kakao.maps.Map(container, {{
                    center: center,
                    level: 4
                }});

                // ì»¤ìŠ¤í…€ ë§ˆì»¤
                var imageSrc = "https://absolute-beryl.vercel.app/public/marker_green.png";
                var imageSize = new kakao.maps.Size(36, 43);
                var imageOption = {{ offset: new kakao.maps.Point(18, 43) }};
                var markerImage = new kakao.maps.MarkerImage(imageSrc, imageSize, imageOption);

                var marker = new kakao.maps.Marker({{
                    position: center,
                    image: markerImage
                }});
                marker.setMap(map);

                map.setDraggable(false);
                map.setZoomable(false);
                map.setKeyboardShortcuts(false);

                // ì „ì—­ì— ì €ì¥í•´ ë‘ê¸°
                window.reportMap = map;
                window.reportMapCenter = center;
                window.reportMapPrintCenter = printCenter;

                function handleBeforePrint() {{
                    if (!window.reportMap) return;
                    window.reportMap.relayout();
                    window.reportMap.setCenter(window.reportMapPrintCenter);
                }}

                function handleAfterPrint() {{
                    if (!window.reportMap) return;
                    window.reportMap.relayout();
                    window.reportMap.setCenter(window.reportMapCenter);
                }}

                window.addEventListener('beforeprint', handleBeforePrint);
                window.addEventListener('afterprint', handleAfterPrint);
                }});
            }};
            document.head.appendChild(script);
            }})();


        </script>
        """
        # ------------------------------
        html = report_service.build_report_html(
            station=station,
            report_date=datetime.now(),
            map_html=map_html,
            terrain_html=terrain_img_html,
            llm_report=llm_report,
            recommendations=combined_recommendations,
            stats_payload=stats_payload,
            parcel_summary=parcel_summary,
            land_payload=land_payload,
            nearby_parcels_available=nearby_parcels is not None and not nearby_parcels.empty,
            map_images=map_images,
        )

        return HTMLResponse(content=html)
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{id}/admin")
async def get_station_admin_info(
    id: str = Path(..., description="ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  ID"),
    service: GeoService = Depends(get_geo_service),
):
    """
    íŠ¹ì • ì£¼ìœ ì†Œ(id)ì˜ í–‰ì •ë™ ê¸°ì¤€ í†µê³„(ì¸êµ¬Â·êµí†µëŸ‰Â·ìƒê¶Œë°€ì§‘ë„Â·ê´€ê´‘ì§€ìˆ˜)
    - station.csv ê¸°ë°˜ raw ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    - í–‰ì •ë™ ì´ë¦„ì€ ë²•ì •ë™ì½”ë“œ(=adm_cd2) â†’ ë²•ì •ë™_ì½”ë“œ.csv ë§¤í•‘
    """

    # 1) station.csv
    df = service.data.get("gas_station")
    if df is None or df.empty:
        raise HTTPException(status_code=500, detail="station.csv ì—†ìŒ")

    df = df.loc[:, ~df.columns.duplicated()]  # ì¤‘ë³µ ì»¬ëŸ¼ ì œê±°

    # 2) ID â†’ lat/lng ë³µêµ¬
    try:
        lat_part, lng_part = id.split("_")
        lat = float(lat_part) / 1_000_000
        lng = float(lng_part) / 1_000_000
    except:
        raise HTTPException(status_code=400, detail="ID í˜•ì‹ ì˜¤ë¥˜")

    # 3) ê°€ì¥ ê°€ê¹Œìš´ station ì°¾ê¸°
    df["distance"] = (df["ìœ„ë„"] - lat)**2 + (df["ê²½ë„"] - lng)**2
    station = df.loc[df["distance"].idxmin()].to_dict()
    station.pop("distance", None)

    # 4) adm_cd2 / ë²•ì •ë™ì½”ë“œ ì¶”ì¶œ
    adm_raw = (
        station.get("ë²•ì •ë™ì½”ë“œ") or
        station.get("adm_cd2") or
        station.get("ë²•ì •ë™ ì½”ë“œ")
    )
    if not adm_raw:
        return {
            "id": id,
            "region": None,
            "population": None,
            "traffic": None,
            "commercial_density": None,
            "tourism": None,
        }

    # â†’ ì´ë¯¸ ìƒë‹¨ì—ì„œ ë¡œë”©í•œ ë³€í™˜ í•¨ìˆ˜ ì‚¬ìš©
    region_name = get_bjd_name_from_adm(adm_raw)

    # 5) station ì›ë³¸ ì§€í‘œ ì¶”ì¶œ
    metrics = {
        "population": station.get("ì¸êµ¬") or station.get("ì¸êµ¬ìˆ˜"),
        "traffic": station.get("êµí†µëŸ‰") or station.get("AADT"),
        "commercial_density": station.get("ìƒê¶Œë°€ì§‘ë„"),
        "tourism": station.get("ê´€ê´‘ì§€ìˆ˜"),
    }

    return {
        "id": id,
        "region": region_name,
        **metrics
    }



@router.get("/{id}/land")
async def get_station_land(
    id: str = Path(..., description="ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  ID (ì˜ˆ: 35689819_128445642)"),
    service: GeoService = Depends(get_geo_service),
):
    """
    íŠ¹ì • ì£¼ìœ ì†Œ(id)ì˜ í•„ì§€ ì •ë³´ API
    - station_with_landprice.csv + station_with_landuse.csv ê¸°ë°˜
    - ID â†’ (lat, lng) ë³µì› â†’ station.csvì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ í–‰ ì°¾ê³ , í•´ë‹¹ PNUë¡œ í•„ì§€ ì •ë³´ ì¡°íšŒ
    """
    try:
        # 1) ê¸°ë³¸ station.csv ë¡œë”©
        df_station = service.data.get("gas_station")
        if df_station is None or df_station.empty:
            raise HTTPException(status_code=500, detail="station.csv ì—†ìŒ")

        df_station = df_station.loc[:, ~df_station.columns.duplicated()]

        if "ìœ„ë„" not in df_station.columns or "ê²½ë„" not in df_station.columns:
            raise HTTPException(status_code=500, detail="ìœ„ë„/ê²½ë„ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

        if "PNU" not in df_station.columns:
            raise HTTPException(status_code=500, detail="PNU ì»¬ëŸ¼ì´ station.csv ì— ì—†ìŠµë‹ˆë‹¤.")

        # 2) ì¢Œí‘œ ê¸°ë°˜ ID íŒŒì‹±
        try:
            lat_part, lng_part = id.split("_")
            lat = float(lat_part) / 1_000_000
            lng = float(lng_part) / 1_000_000
        except Exception:
            raise HTTPException(status_code=400, detail="ID í˜•ì‹ ì˜¤ë¥˜")

        # 3) ê°€ì¥ ê°€ê¹Œìš´ station ì°¾ê¸°
        df_station["distance"] = (
            (df_station["ìœ„ë„"] - lat) ** 2
            + (df_station["ê²½ë„"] - lng) ** 2
        )
        station_row = df_station.loc[df_station["distance"].idxmin()].to_dict()
        station_row.pop("distance", None)

        pnu = str(station_row.get("PNU", "")).strip()
        if not pnu:
            raise HTTPException(status_code=500, detail="_PNU ê°’ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        # --------------------------------------------------
        # 4) ê°œë³„ê³µì‹œì§€ê°€ ì¡°íšŒ (station_with_landprice.csv)
        # --------------------------------------------------
        df_price = load_land_price_df()
        land_price = None

        if df_price is not None:
            matched_price = df_price[df_price["_PNU"] == pnu]

            if not matched_price.empty:
                matched_price = matched_price.copy()
                # ë°ì´í„°ê¸°ì¤€ì¼ì ê¸°ì¤€ ìµœì‹  1ê±´ ì‚¬ìš©
                try:
                    matched_price["ë°ì´í„°ê¸°ì¤€ì¼ì_norm"] = pd.to_datetime(
                        matched_price["ë°ì´í„°ê¸°ì¤€ì¼ì"], errors="coerce"
                    )
                    matched_price = matched_price.sort_values(
                        "ë°ì´í„°ê¸°ì¤€ì¼ì_norm", ascending=False
                    )
                except Exception:
                    pass

                row_p = matched_price.iloc[0]

                raw_price = row_p.get("ê³µì‹œì§€ê°€", "")
                # ìˆ«ìí™” (ì—†ìœ¼ë©´ 0)
                try:
                    price_num = int(float(raw_price or 0))
                except Exception:
                    price_num = 0

                land_price = {
                    "price": price_num,
                    "price_str": f"{raw_price}ì›/ã¡" if raw_price != "" else None,
                    "announce_date": str(row_p.get("ê³µì‹œì¼ì", "")),
                    "type": (str(row_p.get("íŠ¹ìˆ˜ì§€êµ¬ë¶„ëª…", "")) or None),
                    "data_date": str(row_p.get("ë°ì´í„°ê¸°ì¤€ì¼ì", "")),
                }

        # --------------------------------------------------
        # 5) í† ì§€ì´ìš©ê³„íš(ìš©ë„ì§€ì—­Â·ì§€êµ¬ ë“±) ì¡°íšŒ
        #    station_with_landuse.csv
        # --------------------------------------------------
        df_use = load_land_use_df()
        land_use_summary: Dict[str, List[Dict[str, str]]] = {
            "zoning": [],
            "infra": [],
            "environment": [],
            "development": [],
            "other": [],
        }
        land_use_raw: List[Dict[str, str]] = []

        if df_use is not None:
            matched_use = df_use[df_use["_PNU"] == pnu]

            if not matched_use.empty:
                matched_use = matched_use.copy()
                # ì¤‘ë³µ ì œê±° (code + name + date ê¸°ì¤€)
                seen_pairs = set()

                for _, row_u in matched_use.iterrows():
                    code = str(row_u.get("ìš©ë„ì§€ì—­ì§€êµ¬ì½”ë“œ", "")).strip()
                    name = str(row_u.get("ìš©ë„ì§€ì—­ì§€êµ¬ëª…", "")).strip()
                    base_date = str(row_u.get("ë°ì´í„°ê¸°ì¤€ì¼ì", "")).strip()

                    if not code and not name:
                        continue

                    key = (code, name, base_date)
                    if key in seen_pairs:
                        continue
                    seen_pairs.add(key)

                    cat = _classify_landuse(code, name)
                    item = {
                        "code": code,
                        "name": name,
                        "data_date": base_date,
                    }
                    land_use_summary.setdefault(cat, []).append(item)
                    land_use_raw.append(item)

        # ë¹ˆ ì¹´í…Œê³ ë¦¬ëŠ” ì œê±° (í”„ë¡ íŠ¸ì—ì„œ ë‹¤ë£¨ê¸° í¸í•˜ê²Œ)
        land_use_summary = {k: v for k, v in land_use_summary.items() if v}

        # --------------------------------------------------
        # 6) ìµœì¢… ì‘ë‹µ êµ¬ì„±
        # --------------------------------------------------
        response = {
            "id": id,
            "name": station_row.get("field5")
                    or station_row.get("ìƒí˜¸")
                    or station_row.get("name"),
            "address": station_row.get("field6")
                       or station_row.get("ì£¼ì†Œ")
                       or station_row.get("address"),
            "clean_address": station_row.get("_CLEANADDR"),
            "pnu": pnu,
            "location": {
                "lat": float(station_row.get("ìœ„ë„", 0) or 0),
                "lng": float(station_row.get("ê²½ë„", 0) or 0),
            },
            "land_price": land_price,
            "land_use": {
                "summary": land_use_summary,
                "raw": land_use_raw,
            },
        }

        return JSONResponse(content=response)

    except HTTPException:
        raise
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"í•„ì§€ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")


# ============================================================
# ì£¼ìœ ì†Œ ì§€í˜•ë„ API
# ============================================================

pg_dsn = settings.POSTGRES_DSN
terrain_service = TerrainMapService(pg_dsn)

@router.get("/{id}/terrain")
async def get_station_terrain(
    id: str = Path(...),
    service: GeoService = Depends(get_geo_service),
):
    df = service.data.get("gas_station")
    if df is None or df.empty:
        raise HTTPException(status_code=500, detail="station.csv ì—†ìŒ")

    # -----------------------------------------
    # 1) ì¢Œí‘œ ê¸°ë°˜ ID â†’ ìœ„ë„/ê²½ë„ ë³µì›
    # -----------------------------------------
    try:
        lat_part, lng_part = id.split("_")
        lat = float(lat_part) / 1_000_000
        lng = float(lng_part) / 1_000_000
    except:
        raise HTTPException(status_code=400, detail="ID í˜•ì‹ ì˜¤ë¥˜")

    # -----------------------------------------
    # 2) ê°€ì¥ ê°€ê¹Œìš´ station ì°¾ê¸° (report / stats ë°©ì‹ ë™ì¼)
    # -----------------------------------------
    df = df.loc[:, ~df.columns.duplicated()]
    df["distance"] = (df["ìœ„ë„"] - lat)**2 + (df["ê²½ë„"] - lng)**2
    station = df.loc[df["distance"].idxmin()].to_dict()
    station.pop("distance", None)

    # -----------------------------------------
    # 3) terrain ì²˜ë¦¬
    # -----------------------------------------
    lon = station["ê²½ë„"]
    lat = station["ìœ„ë„"]

    bbox = terrain_service.compute_bbox_around(lon, lat, meter=500)
    base_img = terrain_service.fetch_hillshade(bbox, width=768, height=768)
    parcels = terrain_service.query_parcels(lon, lat, radius=500)
    final_img = terrain_service.draw_overlay(base_img, bbox, lon, lat, parcels)

    out_dir = "generated_maps"
    os.makedirs(out_dir, exist_ok=True)
    out_path = os.path.join(out_dir, f"{id}_terrain.png")
    final_img.save(out_path)

    return FileResponse(out_path, media_type="image/png")


from fastapi.responses import HTMLResponse
from app.services.terrain_service import TerrainMapService

@router.get("/{id}/terrain/html", response_class=HTMLResponse)
async def get_station_terrain_html(
    id: str = Path(...),
    service: GeoService = Depends(get_geo_service),
):
    """
    ì£¼ìœ ì†Œ ì£¼ë³€ 300m / 500m í•„ì§€ + ì§€ëª©/ìš©ë„ì§€ì—­ ì¸í„°ë™í‹°ë¸Œ ì§€ë„ (HTML)
    """

    df = service.data.get("gas_station")
    if df is None or df.empty:
        raise HTTPException(status_code=500, detail="station.csv ì—†ìŒ")

    # 1) ì¢Œí‘œ ê¸°ë°˜ ID â†’ ìœ„ê²½ë„ ë³µì›
    try:
        lat_part, lng_part = id.split("_")
        lat = float(lat_part) / 1_000_000
        lon = float(lng_part) / 1_000_000
    except:
        raise HTTPException(status_code=400, detail="ID í˜•ì‹ ì˜¤ë¥˜")

    # 2) ê°€ì¥ ê°€ê¹Œìš´ station ì°¾ê¸°
    df = df.loc[:, ~df.columns.duplicated()]
    df["distance"] = (df["ìœ„ë„"] - lat)**2 + (df["ê²½ë„"] - lon)**2
    station = df.loc[df["distance"].idxmin()].to_dict()
    station.pop("distance", None)

    # 3) HTML ìƒì„±
    html = terrain_service.generate_interactive_html(lon=lon, lat=lat, radius=500)
    return HTMLResponse(content=html)



@router.get("/{id}", response_model=GasStationResponse)
async def get_station_detail(
    id: str = Path(..., description="ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  ID (ì˜ˆ: 35689819_128445642)"),
    service: GeoService = Depends(get_geo_service),
):
    """
    ì¢Œí‘œ ê¸°ë°˜ ê³ ìœ  IDë¡œ ì£¼ìœ ì†Œ ìƒì„¸ ì¡°íšŒ
    """
    try:
        df = service.data.get("gas_station")

        if df is None or df.empty:
            raise HTTPException(status_code=500, detail="ì£¼ìœ ì†Œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        # -------------------------
        # 1) ì¤‘ë³µëœ ìœ„ë„/ê²½ë„ ì»¬ëŸ¼ ì œê±°
        # -------------------------
        # station.csv â†’ rename ê³¼ì •ì—ì„œ "ìœ„ë„", "ê²½ë„"ê°€ 2ê°œì”© ìƒê¹€ â†’ ì´ê±¸ ì œê±°í•´ì•¼ distance ê³„ì‚° ê°€ëŠ¥
        df = df.loc[:, ~df.columns.duplicated()]

        # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
        if "ìœ„ë„" not in df.columns or "ê²½ë„" not in df.columns:
            raise HTTPException(status_code=500, detail="ìœ„ë„/ê²½ë„ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # -------------------------
        # 2) ì¢Œí‘œ ê¸°ë°˜ ID íŒŒì‹±
        # -------------------------
        # ì˜ˆ: "35689819_128445642"
        try:
            lat_part, lng_part = id.split("_")
            lat = float(lat_part) / 1_000_000
            lng = float(lng_part) / 1_000_000
        except Exception:
            raise HTTPException(status_code=400, detail="ID í˜•ì‹ ì˜¤ë¥˜ (ì˜ˆ: 35689819_128445642)")

        # -------------------------
        # 3) ê°€ì¥ ê°€ê¹Œìš´ station ì°¾ê¸°
        # -------------------------
        # ê±°ë¦¬ ê³„ì‚°
        df["distance"] = ((df["ìœ„ë„"] - lat) ** 2 + (df["ê²½ë„"] - lng) ** 2)

        # ìµœì†Œ ê±°ë¦¬ í–‰ ì„ íƒ
        nearest_idx = df["distance"].idxmin()
        station = df.loc[nearest_idx].to_dict()

        # distance ì œê±°
        station.pop("distance", None)

        return JSONResponse(content=station)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
